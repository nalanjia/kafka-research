你好，我是胡夕。今天我要和你分享的主题是：Kafka 请求是怎么被处理的。

无论是 Kafka 客户端还是 Broker 端，它们之间的交互都是通过“请求 / 响应”的方式完成的。比如，客户端会通过网络发送消息生产请求给 Broker，而 Broker 处理完成后，会发送对应的响应给到客户端。

Apache Kafka 自己定义了一组请求协议，用于实现各种各样的交互操作。比如常见的 PRODUCE 请求是用于生产消息的，FETCH 请求是用于消费消息的，METADATA 请求是用于请求 Kafka 集群元数据信息的。

总之，Kafka 定义了很多类似的请求格式。我数了一下，截止到目前最新的 2.3 版本，Kafka 共定义了多达 45 种请求格式。所有的请求都是通过 TCP 网络以 Socket 的方式进行通讯的。

今天，我们就来详细讨论一下 Kafka Broker 端处理请求的全流程。

关于如何处理请求，我们很容易想到的方案有两个。

1.顺序处理请求。如果写成伪代码，大概是这个样子：


while (true) {
            Request request = accept(connection);
            handle(request);
}

这个方法实现简单，但是有个致命的缺陷，那就是吞吐量太差。由于只能顺序处理每个请求，因此，每个请求都必须等待前一个请求处理完毕才能得到处理。这种方式只适用于请求发送非常不频繁的系统。

2. 每个请求使用单独线程处理。也就是说，我们为每个入站请求都创建一个新的线程来异步处理。我们一起来看看这个方案的伪代码。


while (true) {
            Request = request = accept(connection);
            Thread thread = new Thread(() -> {
  handle(request);});
            thread.start();
}

这个方法反其道而行之，完全采用异步的方式。系统会为每个入站请求都创建单独的线程来处理。这个方法的好处是，它是完全异步的，每个请求的处理都不会阻塞下一个请求。但缺陷也同样明显。为每个请求都创建线程的做法开销极大，在某些场景下甚至会压垮整个服务。还是那句话，这个方法只适用于请求发送频率很低的业务场景。

既然这两种方案都不好，那么，Kafka 是如何处理请求的呢？用一句话概括就是，Kafka 使用的是 Reactor 模式。

谈到 Reactor 模式，大神 Doug Lea 的“Scalable IO in Java”应该算是最好的入门教材了。即使你没听说过 Doug Lea，那你应该也用过 ConcurrentHashMap 吧？这个类就是这位大神写的。其实，整个 java.util.concurrent 包都是他的杰作！

好了，我们说回 Reactor 模式。简单来说，Reactor 模式是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。我借用 Doug Lea 的一页 PPT 来说明一下 Reactor 的架构，并借此引出 Kafka 的请求处理模型。

Reactor 模式的架构如下图所示：
【2-配图-Reactor模式的架构.png】

从这张图中，我们可以发现，多个客户端会发送请求给到 Reactor。Reactor 有个请求分发线程 Dispatcher，也就是图中的 Acceptor，它会将不同的请求下发到多个工作线程中处理。

在这个架构中，Acceptor 线程只是用于请求分发，不涉及具体的逻辑处理，非常得轻量级，因此有很高的吞吐量表现。而这些工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。

如果我们来为 Kafka 画一张类似的图的话，那它应该是这个样子的：
【2-配图-为Kafka画一张类似的图.png】

显然，这两张图长得差不多。Kafka 的 Broker 端有个 SocketServer 组件，类似于 Reactor 模式中的 Dispatcher，它也有对应的 Acceptor 线程和一个工作线程池，只不过在 Kafka 中，这个工作线程池有个专属的名字，叫网络线程池。Kafka 提供了 Broker 端参数 num.network.threads，用于调整该网络线程池的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 个网络线程，专门处理客户端发送的请求。

Acceptor 线程采用轮询的方式将入站请求公平地发到所有网络线程中，因此，在实际使用过程中，这些线程通常都有相同的几率被分配到待处理请求。这种轮询策略编写简单，同时也避免了请求处理的倾斜，有利于实现较为公平的请求处理调度。

好了，你现在了解了客户端发来的请求会被 Broker 端的 Acceptor 线程分发到任意一个网络线程中，由它们来进行处理。那么，当网络线程接收到请求后，它是怎么处理的呢？你可能会认为，它顺序处理不就好了吗？实际上，Kafka 在这个环节又做了一层异步线程池的处理，我们一起来看一看下面这张图。
【2-配图-异步线程池.png】

当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个共享请求队列中。Broker 端还有个 IO 线程池，负责从该队列中取出请求，执行真正的处理。如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。

IO 线程池处中的线程才是执行请求逻辑的线程。Broker 端参数 num.io.threads 控制了这个线程池中的线程数。目前该参数默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。你可以根据实际硬件条件设置此线程池的个数。

比如，如果你的机器上 CPU 资源非常充裕，你完全可以调大该参数，允许更多的并发请求被同时处理。当 IO 线程处理完请求后，会将生成的响应发送到网络线程池的响应队列中，然后由对应的网络线程负责将 Response 返还给客户端。

细心的你一定发现了请求队列和响应队列的差别：请求队列是所有网络线程共享的，而响应队列则是每个网络线程专属的。这么设计的原因就在于，Dispatcher 只是用于请求分发而不负责响应回传，因此只能让每个网络线程自己发送 Response 给客户端，所以这些 Response 也就没必要放在一个公共的地方。

我们再来看看刚刚的那张图，图中有一个叫 Purgatory 的组件，这是 Kafka 中著名的“炼狱”组件。它是用来缓存延时请求（Delayed Request）的。所谓延时请求，就是那些一时未满足条件不能立刻处理的请求。比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 acks=all，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。稍后一旦满足了完成条件，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。

讲到这里，Kafka 请求流程解析的故事其实已经讲完了，我相信你应该已经了解了 Kafka Broker 是如何从头到尾处理请求的。但是我们不会现在就收尾，我要给今天的内容开个小灶，再说点不一样的东西。

到目前为止，我提及的请求处理流程对于所有请求都是适用的，也就是说，Kafka Broker 对所有请求是一视同仁的。但是，在 Kafka 内部，除了客户端发送的 PRODUCE 请求和 FETCH 请求之外，还有很多执行其他操作的请求类型，比如负责更新 Leader 副本、Follower 副本以及 ISR 集合的 LeaderAndIsr 请求，负责勒令副本下线的 StopReplica 请求等。与 PRODUCE 和 FETCH 请求相比，这些请求有个明显的不同：它们不是数据类的请求，而是控制类的请求。也就是说，它们并不是操作消息数据的，而是用来执行特定的 Kafka 内部动作的。

Kafka 社区把 PRODUCE 和 FETCH 这类请求称为数据类请求，把 LeaderAndIsr、StopReplica 这类请求称为控制类请求。细究起来，当前这种一视同仁的处理方式对控制类请求是不合理的。为什么呢？因为控制类请求有这样一种能力：它可以直接令数据类请求失效！

我来举个例子说明一下。假设我们有个主题只有 1 个分区，该分区配置了两个副本，其中 Leader 副本保存在 Broker 0 上，Follower 副本保存在 Broker 1 上。假设 Broker 0 这台机器积压了很多的 PRODUCE 请求，此时你如果使用 Kafka 命令强制将该主题分区的 Leader、Follower 角色互换，那么 Kafka 内部的控制器组件（Controller）会发送 LeaderAndIsr 请求给 Broker 0，显式地告诉它，当前它不再是 Leader，而是 Follower 了，而 Broker 1 上的 Follower 副本因为被选为新的 Leader，因此停止向 Broker 0 拉取消息。

这时，一个尴尬的场面就出现了：如果刚才积压的 PRODUCE 请求都设置了 acks=all，那么这些在 LeaderAndIsr 发送之前的请求就都无法正常完成了。就像前面说的，它们会被暂存在 Purgatory 中不断重试，直到最终请求超时返回给客户端。

设想一下，如果 Kafka 能够优先处理 LeaderAndIsr 请求，Broker 0 就会立刻抛出 NOT_LEADER_FOR_PARTITION 异常，快速地标识这些积压 PRODUCE 请求已失败，这样客户端不用等到 Purgatory 中的请求超时就能立刻感知，从而降低了请求的处理时间。即使 acks 不是 all，积压的 PRODUCE 请求能够成功写入 Leader 副本的日志，但处理 LeaderAndIsr 之后，Broker 0 上的 Leader 变为了 Follower 副本，也要执行显式的日志截断（Log Truncation，即原 Leader 副本成为 Follower 后，会将之前写入但未提交的消息全部删除），依 然做了很多无用功。

再举一个例子，同样是在积压大量数据类请求的 Broker 上，当你删除主题的时候，Kafka 控制器（我会在专栏后面的内容中专门介绍它）向该 Broker 发送 StopReplica 请求。如果该请求不能及时处理，主题删除操作会一直 hang 住，从而增加了删除主题的延时。

基于这些问题，社区于 2.3 版本正式实现了数据类请求和控制类请求的分离。其实，在社区推出方案之前，我自己尝试过修改这个设计。当时我的想法是，在 Broker 中实现一个优先级队列，并赋予控制类请求更高的优先级。这是很自然的想法，所以我本以为社区也会这么实现的，但后来我这个方案被清晰地记录在“已拒绝方案”列表中。

究其原因，这个方案最大的问题在于，它无法处理请求队列已满的情形。当请求队列已经无法容纳任何新的请求时，纵然有优先级之分，它也无法处理新的控制类请求了。

那么，社区是如何解决的呢？很简单，你可以再看一遍今天的第三张图，社区完全拷贝了这张图中的一套组件，实现了两类请求的分离。也就是说，Kafka Broker 启动后，会在后台分别两套创建网络线程池和 IO 线程池，它们分别处理数据类请求和控制类请求。至于所用的 Socket 端口，自然是使用不同的端口了，你需要提供不同的 listeners 配置，显式地指定哪套端口用于处理哪类请求。

小结

讲到这里，Kafka Broker 请求处理流程的解析应该讲得比较完整了。明确请求处理过程的最大意义在于，它是你日后执行 Kafka 性能优化的前提条件。如果你能从请求的维度去思考 Kafka 的工作原理，你会发现，优化 Kafka 并不是一件困难的事情。
【2-配图-Kafka处理请求的核心流程盘点.jpg】

开放讨论

坦白来讲，我对社区否定优先级队列方案是有一点不甘心的。如果是你的话，你觉得应该如何规避优先级队列方案中队列已满的问题呢？

欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。

精选留言(36)


cricket1981
双队列设计，分别存放数据类和控制类请求，每次先处理完所有控制类请求再处理数据类请求。
2019-07-27

1

4

明翼
有两种方法：1 是直接替换数据处理队列中的最前面的数据进行处理，处理完控制队列，再将这个消息插队到队头；2 双队列设计，不过双队列，如果先处理控制消息，如果一直来控制消息，数据队列的消息岂不会被延迟很大；

关于复制一套，我看了下面评论，我和部分网友的理解不一样，我觉得是复制一套网络线程持+中间队列+IO线程池；也就是有两个网络线程池，+2个中间队列，和2套IO线程持；

网络线程池作用将数据分发到中间队列，和接受IO线程池的处理结果回复给客户端。我理解为什么要加这个中间队列是为了将网络处理的线程数和IO处理的线程数解耦，达到高性能和资源少占用的目的。
作者回复: 我觉得不错：）

2019-07-28


3

Sunney
老师您好，这两天做项目遇到一个问题想咨询一下，对于网络摄像头的视频流数据和抓拍到的照片数据，kafka应该如何传输呢？
作者回复: 相同的方法，都要传输字节数组。你需要找到合适的方法把你的视频流数据或照片编码成字节序列。当然Kafka其实并不适合传输特别大的消息，因此你可以评估一下是否真的需求传视频本身？
2019-07-29

2

2

ban
老师，社区完全拷贝了这张图中的一套组件，实现了两类请求的分离。也就是说，Kafka Broker 启动后，会在后台分别创建网络线程池和 IO 线程池，它们分别处理数据类请求和控制类请求。

上面这段话不太懂，意思是说：分别建立两套组件（A套 网络线程池IO线程池：负责处理数据类请求)、（B套 网络线程池IO线程池：负责处理控制类请求),这样理解对吗？
作者回复: 嗯嗯，差不多是这个意思
2019-07-28


2

电光火石
优先级队列方案，可以开两个队列，分别处理，前面的监听端口不需要重新构建，只是后面的处理线程不同即可。
另外，想问一下：
1. 为什么当时kafka做的时候，没有考虑使用netty作为通信框架？
2. 对IO这一块的处理比较感兴趣，老师可以介绍一下broker的入口类吗，想去看一下源码
谢谢了！
作者回复: 1. Kafka社区当初主要是为了jar依赖的问题而选择不使用netty，转而使用Java NIO的
2. Broker入口类是kafka.server.KafkaServer.scala
2019-07-27


2

lmtoo
小结部分的图片把数据类请求放到了网络线程池中，而控制类请求放到了IO线程池，弄反了吧；我觉得社区的决定是正确的，这两类请求分离之后，职责更明确了
2019-07-27

2

2

拾光
为什么不直接将Acceptor线程收到的请求存入共享队列，而要引入网络线程池来存？
作者回复: 我认为就是单纯地想要在做一层生产者-消费者分离
2019-12-03


1

锦
我理解Acceptor是用来接收连接的（三次握手），连接成功后把读写请求的Socket提交到网络线程池，网络线程池中的线程通过Selector收到读请求后，从内核读取消息数据，然后再把待处理消息数据放入共享请求队列中。共享请求队列应该是多生产者多消费者模式（这里如何设计比较关键）。io线程池从共享请求队列中取出消息处理，处理完成再把响应提交到网络线程池中，由网络线程池发送至客户端。这里的共享请求队列为什么不直接使用io线程池自带的工作队列呢？另外控制类请求单独走不同线程池处理比较合理。
2019-07-30


1

Riordon
数据类请求和控制类请求的分离，我理解的是多开一套端口，实现一套网络线程池+IO线程池？不对吗？
Acceptor线程：公平转发请求到网络线程
网络线程池：将请求放入共享队列
IO线程池：从共享队列取出请求，执行真正的IO
2019-07-27


1

飞翔
老师 请问有多少线程 在处理请求响应队列里的response消息呀
作者回复: 网络线程池的个数
2019-11-13



飞翔
老师 kafka 为什么不用reactor 最后一种模式 把用boss reactor 和work reactor 模型 而用较简单的第一种reactor
2019-11-13



注定非凡
1 Apache Kafka 自己定义了组请求协议，用于实现各种交互操作。常见有：
a. PRODUCE 请求用于生产消息
b. FETCH请求是用于消费消息
c. METADATA请求是用于请求Kafka集群元数据信息。

Kafka定义了很多类似的请求格式，所有的请求都是通过TCP网络以Socket的方式进行通讯的。

2 KaKfa Broker端处理请求的全流程
A ：常用请求处理方案
a：顺序处理请求
实现方法简答，但吞吐量太差是致命缺陷。因为是顺序处理，每个请求都必须等待前一个请求处理完毕才能得到处理。这只适用于请求发送非常不频繁的系统。
b：每个请求使用单独线程处理
它是完全异步的，每个请求的处理都创建单独线程处理，但缺陷明显，为每个请求都创建线程开销极大，某些场景甚至会压垮整个服务。

B ：Kafka的方案：使用Reactor模式
a：Reactor模式是JUC包作者的作品
b：Reactor模式是事件驱动架构的一种实现方式，特别适应用于处理多个客户端并发向服务端发送请求的场景。

3 Kafka的请求处理方式
A ：Reactor模式中，多个客户端发送请求到Reactor。Reactor有个请求分发线程Dispatcher，它会将不同的请求下发到多个工作线程中处理。
Acceptor线程只用于请求分发，不涉及具体逻辑处理，因此有很高的吞吐量。而工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。

B ：kakfa中，Broker端有个SocketServer组件，类似于Reactor模式中的Dispatcher，他也有对应的Acceptor线程和一个工作线程池，在kafka中，被称为网络线程池。
Broker端参数num.network.threads，用于调整该网络线程池的线程数，默认为4，表示每台Broker启动时，会创建3个网络线程，专门处理客户端发送的请求。

C ：Acceptor线程采用轮询的方式将入站请求公平的发送到所有网络线程中。

D ：当网络线程接收到请求后，Kafka在这个环节又做了一层异步线程池的处理。
（1）当网络线程拿到请求后，她不是自己处理，而是将请求放入到一个共享请求队列中。
（2）Broker端还有个IO线程池，负责从该队列中取出请求，执行真正的处理。如果是PRODUCE生产请求，则将消息写入到底层的磁盘日志中；如果是FETCH请求，则从磁盘或页缓存中读取消息。

E ：IO线程池中的线程是执行请求逻辑的线程。Broker端参数num.io.threads控制了这个线程数，默认为8，表示每台Broker启动后自动创建8个IO线程处理请求。

F ：请求队列是所有网络线程共享的，而响应队列则是每个网络线程专属的。原因在于Dispatcher只是用于请求分发而不负责响应回传，因此只能让每个网络线程自己发送Repsone给客户端，所有这些Response没必要放在一个公共的地方。

G ：Purgatory组件，专门用来缓存延时请求（Delayed Requset）。如设置了acks=all的PRODUCE请求，该请求要必须等待ISR中所有副本都接收了消息后才能返回，此时处理该请求的IO线程就必须瞪大其他Broker的写入结果。当请求不能立即处理时，他就会暂存在Purgatory中。待满足了完成条件，IO线程会继续处理该请求，并将Response放入到对应的网络线程的响应队列中

4 Kafka对请求的处理特点
A ：Kafka Broker对所有的请求都是一视同仁的。
B ：这些请求根据功能，可分为不同的请求类型。从业务的权重角度来讲，是有高低之分的，如控制类请求可以影响数据类请求。
C ：无原则的平等，会造成混乱

社区采取的方案是，同时创建两套完全样的组件，实现两类请求的分离。
2019-11-07



朱东旭
胡老师您好，为什么有时候听到epoll，有时候听到reactor,这俩有啥区别。。
作者回复: 不是一个层级的东西。epoll是一种IO模型，而Reactor是一种IO处理模式（IO pattern）。可以这么说：我们可以使用epoll来实现Reactor
2019-11-02



云师兄
老师能否解答下kafka要分成网络线程和io线程？像tomcat这类请求模型中，网络线程也是执行线程，kafka大费周章，除了延迟请求，还有其他目的吗
作者回复: 我不是设计人员不好妄言：）直观的感受是，可能就是单纯地想把分发线程和处理线程分开吧
2019-10-14



B+Tree
reactor模式特别适合多客户端向服务端请求的场景，同样场景的还有redis
2019-10-09



代码搬运工
控制类请求直接创建新的线程池执行。
2019-09-17



AF
老师可不可以这么理解，这一节其实就是讲的Kafka的网络模型？
作者回复: 可以的：）
2019-09-15



shjdwxy
如果共享请求队列满了，会出现什么问题呢？
作者回复: 相应的线程阻塞住，表现为请求处理延时增加
2019-09-14



DFighting
优先级队列就算解决了队列满的问题也可能造成数据类请求饥饿的问题，既然两者是不同类型的请求，我还是觉得分开设计会避免不少的问题，为以后的优化带来空间，不过有一个问题，控制类请求和数据类请求操作的对象或多或少肯定会有重合，遇到冲突的话现在是怎么解决的呢？
2019-09-09



Algoric
Acceptor单线程是不是存在单点问题？且单线程如果并发量过大会不会出现瓶颈？Netty的Acceptor应该也是使用了线程池吧，希望可以解答一下
作者回复: 由于Acceptor线程只接收请求然后转发，因此非常轻量级。通常情况下都不是瓶颈。你可以监控kafka.network:type=Acceptor,name=AcceptorBlockedPercent,listener={listenerName}来看看Acceptor线程的繁忙程度
2019-09-07



蛋炒番茄
请求队列是所有网络线程共享的，而响应队列则是每个网络线程专属。为什么这样设计，原因没看懂。希望老师讲详细一点
作者回复: 原因就是没必要放在一起，让各自线程自己发送就可以了。类似于：有了任务大家一起分，做完了自己单独汇报就行了
2019-08-28



godtrue
老师好，请教几个小问题。
1：细心的你一定发现了请求队列和响应队列的差别：请求队列是所有网络线程共享的，而响应队列则是每个网络线程专属的。这么设计的原因就在于，Dispatcher 只是用于请求分发而不负责响应回传，因此只能让每个网络线程自己发送 Response 给客户端，所以这些 Response 也就没必要放在一个公共的地方。
只能让每个网络线程自己发送response给客户端，这是否意味着，假如有100个请求就有100个响应的网络线程，那线程的创建比较耗费资源的问题还是存在的呀？

2：使用reactor模式，线程资源的节省是体现在处理线程比网络线程更轻量上嘛？另外处理线程和分发线程都是在同一台服务器还是分布在不同服务器，如果在一台服务器上，他的扩展性怎么实现？

担心优先级队列满的问题，能否将优先级队列也做分割处理，一个逻辑优先级队列被分割在N台物理机上，如果这样这个优先级队列恐怕需要自己实现了，难度比较大，但是一种思路。

我的理解集群具有无限的横向扩展的能力，就是借助了网络通信的力量，将N台物理机组成一个强大的逻辑机，将原来单机处理的资源管理工作上移到集群中有分布式应用框架开发人员来做啦！
2019-08-18



落霞与孤鹜
有点疑问，在说到控制类请求和数据类请求的时候，您说强制执行leaderandisr，leader副本立马失效，follwer副本立马上位，这不就是立马执行了控制类请求么？和下面说的优先处理leaderandisr请求，我咋感觉是一样一样的啊
作者回复: 要执行了LeaderAndIsr才有这个效果啊，如果LeaderAndIsr被阻塞了这个变更的时机就被大大推迟了啊
2019-08-13



Mick
老师麻烦帮我看下这个请求流程图我画的对不对？https://www.processon.com/view/link/5d481e6be4b07c4cf3031755
作者回复: 我觉得挺好的：）
2019-08-05

1


蓝魔丶
回答最后问题：优先队列只能保证优先级高的控制类请求有机会先调度执行，无法保证控制类比数据类请求先处理的要求，同样还可能造成数据类请求饥饿现象，而且数据类请求会比控制类请求多，所以如果放在一个共享队列中，则无法线性扩展，所以使用双队列自己严格控制，数据类请求队列装满的概率大，可以动态扩展数据类请求队列加快处理过程，而对于控制类请求队列则没有影响
2019-08-05



WL
再请问一下老师, IO线程池为啥不涉及成3个共享队列, 一个是写请求共享队列,一个读请求共享队列, 一个控制类共享队列, 这样写消息共享队列因为是顺序写, 所以只用一个线程一直写就可以了, 这样还不需要线程上下文切换; 读请求共享队列因为可能不同消费者组的消费者消费进度不同可以有多个线程, 这样吧读写分开我感觉请求的处理效率可以进一步提高
2019-07-30



WL
请问老师两个问题:
1. 网络线程池是不是在响应客户端上起到的作用更大, 我感觉在请求接受上, networkthread只是把请求放入共享请求队列, 是一个线程放还是多个线程放好像效率上没提高多少.
2. 如果是网络线程池是多个线程同时向共享队列里插入请求,那么怎么保证消息被顺序处理, 很可能后面的消息因为异步的原因先于前面的消息放入共享请求队列
2019-07-30



Hello world
老师，我理解Acceptor线程是分发请求给网络线程，而网络线程接收到请求再放入请求队列。Acceptor线程只是负责转发请求，压力不大，既然网络线程其实也是相当于转发请求，为啥还要有这个网络线程呢？
作者回复: Processor线程也不是啥都不做，它有很多要处理的事情，比如执行网络层的请求/响应发送，这些都是后面API线程或请求处理线程做不了也不应该做的。
2019-07-29



曾轼麟
补充一下前面的留言，外层优先队列只按照请求类来保证优先级，如果每次同类型的请求都有优先级的话，我建议再加一层同类型的内层优先队列，然后在这里面拉出链表，不过实现起来会稍微有点麻烦
2019-07-28



曾轼麟
继续使用优先队列，但是每个队列的节点都是一个node，允许有卫星数据（比如一个链表的引用），当同样等级或者类型的请求可以效仿hashmap发生hash冲突那样拉出一条链表，保存到堆里面，jvm允许的话这样就能拓展不会出现队列满的情况，同时保持着优先队列的特点
2019-07-28



曾轼麟
终于明白为什么broker可以配置两个listener了，那时候我看着官网还挺奇怪的
2019-07-28



rm -rf 😊ི
两者只是分开了，但也没解决上文说的，控制类请求比数据类请求优先的需求呀？希望老师解答一下。
另外，总结图写反了吧，网络线程池应该是处理控制类，IO线程池应该才是处理数据类请求吧？
作者回复: 不是。每类请求都有对应的网络线城市和IO线程池
2019-07-27



AF
共享请求队列的作用是为了缓解上下游的压力吗？
2019-07-27

1


cricket1981
规避优先级队列方案中队列已满的问题可以考虑将队列中后进来的数据类请求清退到另一个队列或持久化到文件，以腾出队列空间给到控制类请求，待队列请求处理完再将其加载回原队列。
2019-07-27



cricket1981
从文章介绍来看社区方案也只是分开处理数据类和控制类请求，并无控制类优先于数据类处理逻辑啊
作者回复: 嗯嗯，从某种意义上只是分离，确实不是我们认为的优先级处理，但总归是能解决之前碰到的那些问题不是：）
2019-07-27



calljson
期待下一讲
2019-07-27

