你好，我是胡夕。今天我要和你分享的内容是：消费者组重平衡能避免吗?

其实在专栏第 15 期中，我们讲过重平衡，也就是 Rebalance，现在先来回顾一下这个概念的原理和用途。Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。但是，在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。

你可能会对这里提到的“协调者”有些陌生，我来简单介绍下。所谓协调者，在 Kafka 中对应的术语是 Coordinator，它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。

具体来讲，Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。

所有 Broker 在启动时，都会创建和开启相应的 Coordinator 组件。也就是说，所有 Broker 都有各自的 Coordinator 组件。那么，Consumer Group 如何确定为它服务的 Coordinator 在哪台 Broker 上呢？答案就在我们之前说过的 Kafka 内部位移主题 __consumer_offsets 身上。

目前，Kafka 为某个 Consumer Group 确定 Coordinator 所在的 Broker 的算法有 2 个步骤。

第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)。
第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。

简单解释一下上面的算法。首先，Kafka 会计算该 Group 的 group.id 参数的哈希值。比如你有个 Group 的 group.id 设置成了“test-group”，那么它的 hashCode 值就应该是 627841412。其次，Kafka 会计算 __consumer_offsets 的分区数，通常是 50 个分区，之后将刚才那个哈希值对分区数进行取模加求绝对值计算，即 abs(627841412 % 50) = 12。此时，我们就知道了位移主题的分区 12 负责保存这个 Group 的数据。有了分区号，算法的第 2 步就变得很简单了，我们只需要找出位移主题分区 12 的 Leader 副本在哪个 Broker 上就可以了。这个 Broker，就是我们要找的 Coordinator。

在实际使用过程中，Consumer 应用程序，特别是 Java Consumer API，能够自动发现并连接正确的 Coordinator，我们不用操心这个问题。知晓这个算法的最大意义在于，它能够帮助我们解决定位问题。当 Consumer Group 出现问题，需要快速排查 Broker 端日志时，我们能够根据这个算法准确定位 Coordinator 对应的 Broker，不必一台 Broker 一台 Broker 地盲查。

好了，我们说回 Rebalance。既然我们今天要讨论的是如何避免 Rebalance，那就说明 Rebalance 这个东西不好，或者说至少有一些弊端需要我们去规避。那么，Rebalance 的弊端是什么呢？总结起来有以下 3 点：

1。Rebalance 影响 Consumer 端 TPS。这个之前也反复提到了，这里就不再具体讲了。总之就是，在 Rebalance 期间，Consumer 会停下手头的事情，什么也干不了。
2。Rebalance 很慢。如果你的 Group 下成员很多，就一定会有这样的痛点。还记得我曾经举过的那个国外用户的例子吧？他的 Group 下有几百个 Consumer 实例，Rebalance 一次要几个小时。在那种场景下，Consumer Group 的 Rebalance 已经完全失控了。
3。Rebalance 效率不高。当前 Kafka 的设计机制决定了每次 Rebalance 时，Group 下的所有成员都要参与进来，而且通常不会考虑局部性原理，但局部性原理对提升系统性能是特别重要的。

关于第 3 点，我们来举个简单的例子。比如一个 Group 下有 10 个成员，每个成员平均消费 5 个分区。假设现在有一个成员退出了，此时就需要开启新一轮的 Rebalance，把这个成员之前负责的 5 个分区“转移”给其他成员。显然，比较好的做法是维持当前 9 个成员消费分区的方案不变，然后将 5 个分区随机分配给这 9 个成员，这样能最大限度地减少 Rebalance 对剩余 Consumer 成员的冲击。

遗憾的是，目前 Kafka 并不是这样设计的。在默认情况下，每次 Rebalance 时，之前的分配方案都不会被保留。就拿刚刚这个例子来说，当 Rebalance 开始时，Group 会打散这 50 个分区（10 个成员 * 5 个分区），由当前存活的 9 个成员重新分配它们。显然这不是效率很高的做法。基于这个原因，社区于 0.11.0.0 版本推出了 StickyAssignor，即有粘性的分区分配策略。所谓的有粘性，是指每次 Rebalance 时，该策略会尽可能地保留之前的分配方案，尽量实现分区分配的最小变动。不过有些遗憾的是，这个策略目前还有一些 bug，而且需要升级到 0.11.0.0 才能使用，因此在实际生产环境中用得还不是很多。

总而言之，Rebalance 有以上这三个方面的弊端。你可能会问，这些问题有解吗？特别是针对 Rebalance 慢和影响 TPS 这两个弊端，社区有解决办法吗？针对这两点，我可以很负责任地告诉你：“无解！”特别是 Rebalance 慢这个问题，Kafka 社区对此无能为力。“本事大不如不摊上”，既然我们没办法解决 Rebalance 过程中的各种问题，干脆就避免 Rebalance 吧，特别是那些不必要的 Rebalance。

就我个人经验而言，在真实的业务场景中，很多 Rebalance 都是计划外的或者说是不必要的。我们应用的 TPS 大多是被这类 Rebalance 拖慢的，因此避免这类 Rebalance 就显得很有必要了。下面我们就来说说如何避免 Rebalance。

要避免 Rebalance，还是要从 Rebalance 发生的时机入手。我们在前面说过，Rebalance 发生的时机有三个：

组成员数量发生变化
订阅主题数量发生变化
订阅主题的分区数发生变化

后面两个通常都是运维的主动操作，所以它们引发的 Rebalance 大都是不可避免的。接下来，我们主要说说因为组成员数量变化而引发的 Rebalance 该如何避免。

如果 Consumer Group 下的 Consumer 实例数量发生变化，就一定会引发 Rebalance。这是 Rebalance 发生的最常见的原因。我碰到的 99% 的 Rebalance，都是这个原因导致的。

Consumer 实例增加的情况很好理解，当我们启动一个配置有相同 group.id 值的 Consumer 程序时，实际上就向这个 Group 添加了一个新的 Consumer 实例。此时，Coordinator 会接纳这个新实例，将其加入到组中，并重新分配分区。通常来说，增加 Consumer 实例的操作都是计划内的，可能是出于增加 TPS 或提高伸缩性的需要。总之，它不属于我们要规避的那类“不必要 Rebalance”。

我们更在意的是 Group 下实例数减少这件事。如果你就是要停掉某些 Consumer 实例，那自不必说，关键是在某些情况下，Consumer 实例会被 Coordinator 错误地认为“已停止”从而被“踢出”Group。如果是这个原因导致的 Rebalance，我们就不能不管了。

Coordinator 会在什么情况下认为某个 Consumer 实例已挂从而要退组呢？这个绝对是需要好好讨论的话题，我们来详细说说。

当 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。如果某个 Consumer 实例不能及时地发送这些心跳请求，Coordinator 就会认为该 Consumer 已经“死”了，从而将其从 Group 中移除，然后开启新一轮 Rebalance。Consumer 端有个参数，叫 session.timeout.ms，就是被用来表征此事的。该参数的默认值是 10 秒，即如果 Coordinator 在 10 秒之内没有收到 Group 下某 Consumer 实例的心跳，它就会认为这个 Consumer 实例已经挂了。可以这么说，session.timout.ms 决定了 Consumer 存活性的时间间隔。

除了这个参数，Consumer 还提供了一个允许你控制发送心跳请求频率的参数，就是 heartbeat.interval.ms。这个值设置得越小，Consumer 实例发送心跳请求的频率就越高。频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更加快速地知晓当前是否开启 Rebalance，因为，目前 Coordinator 通知各个 Consumer 实例开启 Rebalance 的方法，就是将 REBALANCE_NEEDED 标志封装进心跳请求的响应体中。

除了以上两个参数，Consumer 端还有一个参数，用于控制 Consumer 实际消费能力对 Rebalance 的影响，即 max.poll.interval.ms 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求，Coordinator 也会开启新一轮 Rebalance。

搞清楚了这些参数的含义，接下来我们来明确一下到底哪些 Rebalance 是“不必要的”。

第一类非必要 Rebalance 是因为未能及时发送心跳，导致 Consumer 被“踢出”Group 而引发的。因此，你需要仔细地设置 session.timeout.ms 和 heartbeat.interval.ms 的值。我在这里给出一些推荐数值，你可以“无脑”地应用在你的生产环境中。

设置 session.timeout.ms = 6s。
设置 heartbeat.interval.ms = 2s。
要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms >= 3 * heartbeat.interval.ms。

将 session.timeout.ms 设置成 6s 主要是为了让 Coordinator 能够更快地定位已经挂掉的 Consumer。毕竟，我们还是希望能尽快揪出那些“尸位素餐”的 Consumer，早日把它们踢出 Group。希望这份配置能够较好地帮助你规避第一类“不必要”的 Rebalance。

第二类非必要 Rebalance 是 Consumer 消费时间过长导致的。我之前有一个客户，在他们的场景中，Consumer 消费数据时需要将消息处理之后写入到 MongoDB。显然，这是一个很重的消费逻辑。MongoDB 的一丁点不稳定都会导致 Consumer 程序消费时长的增加。此时，max.poll.interval.ms 参数值的设置显得尤为关键。如果要避免非预期的 Rebalance，你最好将该参数值设置得大一点，比你的下游最大处理时间稍长一点。就拿 MongoDB 这个例子来说，如果写 MongoDB 的最长时间是 7 分钟，那么你可以将该参数设置为 8 分钟左右。

总之，你要为你的业务处理逻辑留下充足的时间。这样，Consumer 就不会因为处理这些消息的时间太长而引发 Rebalance 了。

如果你按照上面的推荐数值恰当地设置了这几个参数，却发现还是出现了 Rebalance，那么我建议你去排查一下 Consumer 端的 GC 表现，比如是否出现了频繁的 Full GC 导致的长时间停顿，从而引发了 Rebalance。为什么特意说 GC？那是因为在实际场景中，我见过太多因为 GC 设置不合理导致程序频发 Full GC 而引发的非预期 Rebalance 了。

小结

总而言之，我们一定要避免因为各种参数或逻辑不合理而导致的组成员意外离组或退出的情形，与之相关的主要参数有：

session.timeout.ms
heartbeat.interval.ms
max.poll.interval.ms
GC 参数

按照我们今天所说的内容，恰当地设置这些参数，你一定能够大幅度地降低生产环境中的 Rebalance 数量，从而整体提升 Consumer 端 TPS。
【09-配图-避免消费者组非必要Rebalance的方法.jpg】

开放讨论

说说在你的业务场景中，Rebalance 发生的频率、原因，以及你是怎么应对的，我们一起讨论下是否有更好的解决方案。

欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。

精选留言(57)


Icedmaze
在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待Rebalance的完成。
这里想问的是，如果我有一个长耗时的业务逻辑需要处理，并且offset还未提交，这时候系统发生了Rebalance的话，是等待所有消费端当前消息都处理完成，再进行停止消费，并进行重新分配分区，还是说强制停止消费。
如果强制停止消费的话，那么那些已经处理完成一半的数据并offset未提交的数据，势必会导致Rebalance后重新进行消费，导致数据产生重复消费。
作者回复: 你所谓的处理是指业务上的处理逻辑。对于Kafka而言，从poll方法返回消息的那一刻开始这条消息已经算是“消费”完成了。
2019-07-11

5

15

墨渊战神01
Consumer 消费时间过长为啥会导致rebalance？是不能及时发心跳 导致coordinator认为该consumer挂了吗？
作者回复: consumer主动关闭会主动向Coordinator发送LeaveGroup请求，从而让Coordinator第一时间开启rebalance
2019-07-11


5

千屿
我遇到一个很奇怪的问题，我消费者单线程使用订阅模式消费主题，主题下有三个分区，但是每次启动消费者，只能消费到一个分区的数据，在启动的日志里已经显示了该group已经分配到了三个分区，可是只会poll一个分区的数据。当我用多线程启动三个消费者实例是正常的，启动两个实例只能消费到两个分区数据，求各位大神指点下，谢谢了!
作者回复: 是否是因为某个分区的数据量太多，造成了其他分区的“假饿死”？
2019-07-11

1

4

丘壑
根据公式计算记过：partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)只可能是一个分区值，该分区值对于的leader副本的broker也只可能是集群中的一台，那么一个group进行位移提交的时候，只能是与集群中的一台broker进行交互了？这样是不是就会有性能瓶颈啊，没有充分利用集群中的broker啊，
作者回复: 不同的group id会被哈希到不同的分区上，从而不同的broker能充当不同group的Coordinator
2019-07-11


4

Liam
问个小白问题，如何排查得知broker rebalance 过多，通过broker日志吗？什么日志呢
作者回复: 去找Coordinator所在的broker日志，如果经常发生rebalance，会有类似于"(Re)join group" 之类的日志
2019-07-11

3

3

诗泽
如果同一个group 的不同consumer 设置的session.timeout.ms 的不一样怎么办？协调者以最后一个consumer 为准吗？
作者回复: 取最大的
2019-07-11

1

2

李奕慧
“每个 Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。”这个是后台自动触发的还是每次主动poll消息触发的啊？
作者回复: 0.10.1之前是在调用poll方法时发送的，0.10.1之后consumer使用单独的心跳线程来发送
2019-07-11

1

2

巧克力黑
Spark Streaming消费Kafka的日志中，会有很多Marking the coordinator xxx:9092 (id: 2147483645 rack: null) dead for group xxx_etl日志。请教老师，这是什么原因引起的，对消费者任务有影响么？
作者回复: 很多种原因而且如果我没记错的话，这是个INFO日志，你最好调整一下日志级别，看看能否打出真实的原因。从这个错误本身来看，这个异常就是表示consumer无法连接上Coordinator或Coordinator本身不可用了，可能的原因确实太多了
2019-09-11


1

godtrue
1：rebalance是啥？
Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。但是，在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。

2：rebalance有啥弊端？
2-1：Rebalance 影响 Consumer 端 TPS。这个之前也反复提到了，这里就不再具体讲了。总之就是，在 Rebalance 期间，Consumer 会停下手头的事情，什么也干不了。
2-2：Rebalance 很慢。如果你的 Group 下成员很多，就一定会有这样的痛点。还记得我曾经举过的那个国外用户的例子吧？他的 Group 下有几百个 Consumer 实例，Rebalance 一次要几个小时。在那种场景下，Consumer Group 的 Rebalance 已经完全失控了。
2-3：Rebalance 效率不高。当前 Kafka 的设计机制决定了每次 Rebalance 时，Group 下的所有成员都要参与进来，而且通常不会考虑局部性原理，但局部性原理对提升系统性能是特别重要的。

3：rebalance啥时候发生？
3-1：组成员数量发生变化
3-2：订阅主题数量发生变化
3-3：订阅主题的分区数发生变化

4：rebalance的算法是啥？
4-1：全员参与的分区分配策略——目前的算法，也是rebalance慢的根源
4-2：粘性的分区分配策略——尽量不动没有问题的分区，重新分配有问题的分区

5：rebalance能否避免？
不能完全避免
只能最大限度的设置更为合理的参数，来避免非必要的rebalance，比如这些参数
5-1：session.timeout.ms
5-2：heartbeat.interval.ms
5-3：max.poll.interval.ms
5-4：GC参数

疑问？
rebalance的算法为啥最早是全员参与的方式？kafka起源于大数据，估计分区数比较多的情况应该早已经猜到。
另外，粘性的分区分配策略具体是怎么实现的，听起来不难，但是写kafka的人都实现的不佳，想必不是那么容易的，老师觉得实现的痛点在哪里？
2019-08-16


1

小头针
胡老师，请问后面会讲到controller么？因为它也涉及到选举，请问controller的选举机制又是怎样的呢？
作者回复: 会讲到controller，如果有未涉及的部分， 也可以直接在这里留言提问 ：）
2019-07-15


1

小白
一个consumer group下的多个consumer部署在k8s上，每次发布新版本滚动升级的过程，就是不断发生Rebalance的过程好像没有太好的解决办法。
2019-07-14


1

花开成海
请问，内部topic可以增加分区数量吗？有实践过吗？有一个很大集群，内部topic某个分区的副备偶发的被剔除isr然后再加入，观察发现这个分区的写入较大，所以希望增加分区数量。
作者回复: 别增加。目前源代码中内部topic的分区被hard code成50了，如果后面修改会造成各种问题。已经有对应的bug来解决此事了，但代码还没有merge
2019-07-12


1

Icedmaze
那可否认为，之前poll的数据还是会被继续进行业务逻辑处理，若在rebalance停止消费期间offset并未进行提交，可能会造成该partition里面的同一批消息被重新分配给其他消费实例，造成重复消费问题。
作者回复: 是的
2019-07-12


1

lmtoo
这个Rebalance是针对ConsumerGroup消费的某一个主题的，还是针对所有消费主题的？如果给消费者组增加了一个新的topic，会对该ConsumerGroup在其他已经消费的主题再平衡吗？
作者回复: 针对整个group的。如果消费者组订阅信息发生变化也是会发生rebalance的。
2019-07-11

2

1

ikimiy
0.9版本里面好像没有最长消费时间参数max.poll.interval.ms，在0.9版本中如何控制消费时长
关于GC的设置，老师后续会有讲到吗？应该如何设置是最佳实践

作者回复: 0.9的确没有这个参数。你依然只能设置session.timeout.ms来规避

2019-07-11


1

美美
为啥rebalance很慢没有解释
2019-11-25



James
请问一下
brokder挂了,不会导致订阅主题的分区数发生变化吗,然后重平衡
作者回复: broker挂了，分区数不会变啊
2019-11-13



James
今天出现Rebalance,但是还是不知道是什么原因.
不知道是gc,还是因为Rebalance导致gc..还是参数的设置不合理.(有数据处理后插入redis),好像也有出现broker一个节点挂了. 问题真多都不知道是什么原因.慢慢排查吧(累死了)
2019-11-13



注定非凡
1 什么是重平衡
A ：让一个Consumer Group下所有的consumer实例就如何消费订阅主题的所有分区达成共识的过程。
B ：在重平衡过程中，所有Consumer实例共同参与，在协调者组件的帮助下，完成订阅分区的分配。
C ：整个过程中，所有实例都不能消费任何消息，因此对Consumer的TPS影响很大

2 为什要避免重平衡
A ：Rebalance影响Consumer端的TPS，因为重平衡过程中消费者不能消费消息
B ：Rebalance很慢，如果有数百个消费者实例，整个过程耗时可能达到几个小时
C ：Rebalance效率低，这个过程是全员参与，通常不考虑局部性原理，但局部性原理对系统性能提升特别重要。
D ：真实的业务场景中，很多Rebalance都是计划外或是不必要的。

3 何时会触发重平衡
A ：组成员数量发生变化
B ：订阅主题数量发生变化
C ：订阅主题分区数发生变化。

4, 要避免哪些重平衡
最常见的是消费者数发生变化触发的重平衡，其他的重平衡是不可避免的，但消费者数量变化是可避免的

A ：Consumer实例增加
当启动一个配置相同的group.id值的consumer程序时，就是向这个组中增加一个消费者实例，这中秋情况一般是我们为了提升消费者端的TPS，是计划内的，所以也不用避免。

B ：Consumer实例减少
（1）按计划的减少消费者实例，同样不用避免
（2）计划外的减少触发的重平衡才是我们要关注的。

5 如何避免重平衡
在某些情况下，Consumer实例会被Coordinateor错误地认为“已停止”，进而被踢出Group。这种情况导致的重平衡是需要避免的。

A ：Consumer实例不能及时的发送心跳请求
当消费者组完成重平衡后，每个Consumer实例都会定期地向Coordinator发送心跳请求，如这个心跳请求没有被及时发送，Coordinator就会认为该Consumer已经掉线，将其从组中移除，并开启新一轮重平衡。

解决：Consumer端设置：
》Session.timeout.ms：默认为10秒，表示10秒内Coordinator没有收到Group下某个Consumer实例的心跳，就认为实例下线。这个可以适当的增大
》heartbeat.interval.ms：控制发送心跳请求的频率，频繁的发送心跳请求会额外消耗带库资源。
》max.poll.interval.ms：限定Consumer端应用程序两次调用poll方法的最大时间间隔。默认值是5分钟，表示如果Consumer程序在5分钟之内无法消费完poll方法返回的消息，那么consumer会主动的发起“离开组”的请求，

建议：session.timeout.ms=6s
Heartbeat.interval.ms=2s
保证Consumer实例在判定为“dead”之前，能够发送至少3轮的心跳请求，即session.timeout.ms >=3 * heartbeat.interval.ms。

B ：Consumer消费时间过长
消费者端处理了一个很重的消费逻辑，耗时较长，导致Consumer端应用程序两次调用poll方法的时间超出设置的最大时间间隔。

解决：
                    1，将max.poll.interval.ms参数设置较大一些
                    2，优化消费者端业务逻辑，压缩消费耗时

C ：GC影响
Consumer端的GC表现也会导致频繁的重平衡，频繁的Ful GC会导致长时间的断顿。
解决：
JVM调优。
2019-11-04



rhwayfun
觉得很有必要实现粘性分区分配（局部性原理），我觉得实现起来应该不难，为啥一直不推出呢
作者回复: 新版本已经推出来了
2019-11-01



巧克力黑
Spark Streaming做为消费者，batch时间间隔是40s，使用kafka-consumer-groups.sh --bootstrap-server local:9092 --describe --group test_v1命令，发现CONSUMER-ID一直有变化。如果batch间隔是20s则CONSUMER-ID一直保持不变。
请问老师这个是什么情况？kafka consumer的分配怎么被spark batch的间隔影响到呢？ 我需要关注session.timeout.ms么？
目前用的是kafka版本是kafka_2.11-0.11.0.2，session.timeout.ms=10秒，要是老版本的30s貌似会更好理解一些
作者回复: 不太清楚你是用的哪种模式（Direct/Receiver）。从输出来看consumer id变化就是生成了新的消费者实例。你可以关注下Kafka端的日志，看看是否存在group rebalance的情况。当然如果你使用的是Direct模式，应该不存在rebalance，因为压根也没有使用group机制。
2019-10-24

1


绿箭侠
胡大，请问GC的问题只是在实现Consumer JAVA API的情况下才需要考虑的呗？比如我使用C++ 的API呢？！
作者回复: C++应该没有向Java GC的担忧吧：）
2019-10-15



miwucc
从0.10.1.x开始，客户端貌似已经把心跳线程和业务线程分开了，这样的话max.poll.interval.ms还是会影响心跳导致rebanlance吗？另外加入某个broker主分区挂掉，broker重新选组是不是也要引发reblance？
作者回复: 会的。max.poll.interval.ms是rebalance的超时时间。broker端Coordinator挂掉不会引发rebalance
2019-09-16

1


樱花落花
老师问个问题，max.poll.interval.ms是拉取的时间间隔，如果过了这个时间没有拉取则会发生重平衡，但是什么情况consumer会不拉取呢？上面mongodb的例子那是业务逻辑处理重，但是对于kafka来说poll()之后就已经算是消费完了，为啥这个参数的设置还要依赖消费的后序业务处理？
作者回复: 因为poll和业务处理通常是在一个线程中，因此业务处理速度会影响poll调用频率
2019-09-06

1


蛋炒番茄
kafka中消费者与broke有几种保持心跳的方式？
1、每次消费者调用poll拉取数据的时候都会向上报心跳？

2、heartbeat.interval.ms该参数也可以控制上报心跳？
是否还有其他的方式？
求指点

这两个参数有啥区别，为什么要这两种两种渠道保持心跳？
作者回复: 1. 单独的心跳线程汇报，不是poll调用时上报
2. 该参数控制心跳频率，没有其他方式能做到这点
3. 你只提到了一个参数，另一个参数是什么？？
2019-08-28



EricJones
```
$ bin/kafka-topics.sh --zookeeper localhost:2181 --topic __consumer_offsets --describe
```
知道了。
2019-07-31



EricJones
查找 Coordinator 的第二步算法，如何查看 12 分区 的 Leader 副本呢？我有一个kafka集群 三个实例，结果我查看的时候只有第一个实例的数据目录下有 __consumer_offsets 目录有五十个。其他的两个实例下面并没有。我要怎么查看 12 分区 的 Leader 副本呢？
作者回复: 使用kafka-topics --describe 查看
2019-07-31

1


大楷
老师好，请问Apache Pulsar如何，它貌似解决了kafka目前的一些痛点，未来是否可以代替kafka呢
2019-07-26



其实我很屌
老师你好，问下，一个group.id内所有topic和分区的消费信息都是放在offset topic的一个分区里吗？
作者回复: 嗯，是的
2019-07-19



天天向上
一个poll线程 拉下来一批数据假设1000条，然后在并发处理，分10个并发线程消费，谁消费完谁提交位移，这样的场景如何处理？
Max不回退原则？对每次的位移提交设置全局最大值记录？如果小位移的批次消费失败就丢消息啦！
不控制原则？谁消费完就各种提交自己的位移？最后一次提交恰好是第一批次，尴尬啦，要有大量重复消费

拉取线程内就地消费原则？

这些问题麻烦给教导下，谢谢
2019-07-18

6


pain
现在好像有单独的线程发送心跳了。消费时间长也没有关系了吧
2019-07-18



外星人
您好，请问对内部主题__consumer_offset做reassign会不会导致rebalance？做reassign过程中，cosumer端commit失败，会不会重试？重试逻辑是怎样的啊？还有没有其他影响呢？谢谢
作者回复: 不会。rebalance是针对消费者组而言的，但迁移任何主题的分区都要小心，尽量避免业务高峰吧。
2019-07-16



电光火石
“基于这个原因，社区于 0.11.0.0 版本推出了 StickyAssignor，即有粘性的分区分配策略。” 现在已经到2.3了，这个测量的稳定性有好转吗？可以生产使用吗？
作者回复: 嗯嗯，2.3修复了之前StickyAssignor的一个重大bug，可以试试看：）
2019-07-14



Chloe
谢谢老师，全部都是干货啊！
2019-07-14



wykkx
老师今天提到这几个参数，貌似都不能避免Rebalance，而是尽快让Rebalance发生吧。。。。。。 如果是要尽量避免的话，session.timeout.ms和max.poll.interval.ms都应该设置的大一些，来增加时间窗口，过滤掉网络抖动或者个别情况下下游处理慢的情况。
2019-07-13

1


rm -rf 😊ི
有个问题，就是上面说的max.poll.interval.ms的设置，我看留言里面说的，poll方法返回的那一刻消息就是消费完成了，那为什么会有这句话："它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完成..."
作者回复: 因为通常我们拿到数据之后还要处理，然后会再次调用poll方法
2019-07-13



z.l
”0.10.1之前是在调用poll方法时发送心跳的的，0.10.1之后consumer使用单独的心跳线程来发送“，是否意味着0.10.1之前如果一批消息的消费时间超过了session.timeout.ms，也会触发rebalabce?此时是不是应该保证max.poll.records个消息的消费时间必须小于session.timeout.ms？
作者回复: 是的
2019-07-12



calljson
在一个session.timeout.ms周期内，如果consumer重启了，relalance是否就可以避免？
作者回复: consumer重启了，rebalance就开始了
2019-07-12



趙衍
关于@Icedmaze提出来的问题，如果Consumer的poll返回了，此时Consumer还没有消费数据就发生了Rebalance，这个分区被分配给另一个消费者。这不是会导致之前还没被消费的消息丢失吗。因为我还没有消费，就提交了offset，导致Coordinator误认为Consumer已经消费了这条消息。
2019-07-12

2


天天~
老师您好，我们的consumer是部署在某个项目中，线上有2个实例，那岂不是每次该项目上线部署时，都会触发Rebalance？
作者回复: 嗯，是这样的。
2019-07-12



其实我很屌
老师你好，接上面Kafka-6030那个issue的问题。我们是自己的topic数据不被清理，一直增长。内置的__consumer_offsets比较健康。有好几个疑问：1、我看了我们实际跑着的kafka的源码，在Log.scala关于日志清理有一句 def size: Long = logSegments.map(_.size).sum，这句话在我segment是500M，保留5G的情况下，是不是会int溢出了？因为我至少有5G的数据，就是50亿+，但是int只能容纳21亿，所以我在想是不是这里除了问题，导致每次程序制定到这里线程崩溃。这是kafka0.11.0的源码，现在gitLab上已经改了，不是这么写的了，但这是我们生产安装的包里带的source。2、我看log-cleaner.log为何只有__consumer_offsets这个topic的清理日志，其他健康的topic怎么都不在这里有日志啊？3、log cleaner和log清除是一回事吗，不太理解LogManager和LogCleaner的分工。我看LogManager里并不需要LogCleaner就能删除日志片段好像。4、LogManager.scala里的startup，启动了一个kafka-log-retention和一个kafka-delete-logs线程任务，这两个区别是啥？我scala不懂，好难读下去。麻烦老师有空帮忙解答下，尤其是第一个，感谢~
2019-07-12



WL
再问一次老师消费者组可以很快的感知到Rebalance后接下来比较好的做法是什么呢，我认为感知应该不是目的而是知道下一步行动的信号，那比较好的下一步行动应该是啥？
作者回复: 刚快地感知rebalance的好处就是能更快地参与到rebalance过程中，省的做无用功了。
2019-07-12



nightmare
rebalance的时候必须等所有消费者都提交offset吗？如果没有提交，reblance这么保证精准一次的语义
作者回复: 不能保证~
2019-07-11



其实我很屌
老师你好，生产上遇到一个问题，log.retention.bytes配置的5g，log.segment.bytes是500m，然后这个topic就一直不会被清理，空间一直增长，已经十几g了单分区单副本，请问是触发了bug吗，见KAFKA-6030，急，求老师指教
作者回复: 是你自己的非compact topic还是内部topic？它们是不同的策略。如果是compact topic，然后空间一直增长，那么有可能触发了其他的bug，应该不是这个bug。你可以用jstack去检查一下Log cleaner thread的运行状态。通常都是因为这个线程挂了导致没法执行compaction了。

如果你的topic不是compact的，那就很奇怪了，你最好提供更多的信息，比如日志是否出现错误等。
2019-07-11

2


RouGE
假设这样的场景：开始groupa下只有一个consumer1，只注册在topic1下面。后来groupa下来了另一个consumer2，只注册在topic2下面。会发生rebalance吗？
作者回复: 会的。组成员发生了变更
2019-07-11

1


WL
想问一下老师，配置session.timeout.ms和heartbeat.interval.ms让Coordinator马上识别出哪个Consumer出问题了就可以避免Rebalance了吗？ 如果不能避免即使快速识别出来感觉也于事无补了啊
作者回复: 不是避免rebalance，而是更快地感知到failure以及更快地感知到rebalance已经开启
2019-07-11



尔我
之前我们从0.9.0.0升级到0.10.2.0版本时，日志消费高峰期发生过每30s触发一次reblance的情况；查看官方文档发现版本变更中有这么一条“Java consumer now shuts down gracefully. By default, the consumer waits up to 30 seconds to complete pending requests. A new close API with timeout has been added to KafkaConsumer to control the maximum wait time.” 我的理解应该是默认情况下kafka等待 consumer处理一条消息超过30s没有提交offset的话就把这个consumer标记为下线然后就触发reblance，但是查看max.poll.interval.ms参数默认设置是300000(300s),感觉不是这个参数限制的，求老师解惑。
作者回复: 这个30秒是写死在代码中的，不是由参数控制的。不过你可以调用带参数的close方法来指定关闭等待时长
2019-07-11



yhh
想问下，如果消费者的业务处理时间不可控，比较难预知，，为避免Rebalance和消息重复消费，这种有什么好的解决办法吗？max.poll.interval.ms设得非常大？
作者回复: 也可以适当减少max.poll.records
2019-07-11



dream
Consumer Group 确定 Coordinator 所在的 Broker 的算法的第二步中说：“找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。”，为什么不是 leader 所在的 broker ，而是 Leader 副本所在的 Broker？
作者回复: Leader和Leader副本是一个意思~~ Leader、Follower本来就是对副本而言的，分区和broker没有什么leader的概念啊
2019-07-11



dream
请问，由于一段时间内没有 producer 往 kafka 里面写消息，导致 Consumer 组中没有消息，这个时间超过 max.poll.interval.ms 的设置，那 consumer 会离开组吗？那如果过一段时间有消息写入 kafka ，consumer 会怎么样？
作者回复: 只要你的consumer调用poll方法就没事。和有没有新消息产生没关心
2019-07-11

1


yhh
max.poll.interval.ms，在这个时间内不能消费完一次poll的消息，就要让它离开消费者组，感觉是不是有点粗暴的？还有怎么才算是消费完消息，是要提交位移吗？
作者回复: 消费完消息后需要再次调用poll方法才行。
2019-07-11



刘易宁
在官方文档上面看到：heartbeat.interval.ms必须设置为session.timeout.ms以下，通常应设置不高于session.timeout.ms的1/3。请问这样设置的原因是什么呢？
作者回复: 试想如果heartbeat.interval.ms > session.timeout.ms，那么当下次发送心跳时，会话已经过期了，心跳也就没有意义了
2019-07-11



曹操
将 session.timeout.ms 设置成 6s 主要是为了让 Coordinator 能够更快地定位已经挂掉的 Consumer。

尽快发现已经挂掉的consumer好像不能避免rebalance
kafka默认时间10s，这个时间间隔设置长一点是不是能避免由于网络不稳导致的心跳发送不及时问题，这样是不是能更好的避免rebalance？
作者回复: 如果是之前的版本，设置该参数长一点是有意义的。有了max.poll.interval.ms之后，session.timeout.ms就唯一被用于检测failed consumer了。所以还是尽早发现为好吧
2019-07-11



明翼
我们遇到的问题和老师案例中很像是因为消费的数据处理逻辑太重造成的超时，以前0.8.2版本，session_timeout和那个最大时间间隔参数是一起的只能加大这个参数的配置。
有个问题请教下，为什么文中设置了session_timeout为6秒尽快剔除死掉的消费者能够避免平衡那？如果有gc超过了6s，岂不是增加了重新平衡的次数
作者回复: hmmm..... 如果GC超过了6s，感觉还是先解决GC为好：）
2019-07-11



30斤的大番薯
胡老师，请问在关闭了reblance的情况下，我多个消费者轮流重新启动的话，所有分区的任务会不会最新压到了一个消费者身上？或者说启动的时候刚开始只有一个消费者，后面才逐渐增加消费者，新增加的消费者如果没有reblance的话如何可以能接管一部分分区呢？
作者回复: "关闭了rebalance" ？如果你使用consumer group是没法关闭rebalance的，而且你只能依赖rebalance帮你做这件事情。

或者你自己来做且不使用consumer group机制
2019-07-11



honnkyou
session.timeout.ms为什么设置在customer端而不是coordinator端？
作者回复: 每个consumer可能设置不同的session.timeout.ms
2019-07-11



kursk.ye
为什么“订阅主题数量发生变化”会引发rebalance?
作者回复: 因为有新的分区需要被分配
2019-07-11

