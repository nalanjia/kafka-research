你好，我是胡夕。今天我要和你分享的主题是：如何配置 Kafka 无消息丢失。

一直以来，很多人对于 Kafka 丢失消息这件事情都有着自己的理解，因而也就有着自己的解决之道。在讨论具体的应对方法之前，我觉得我们首先要明确，在 Kafka 的世界里什么才算是消息丢失，或者说 Kafka 在什么情况下能保证消息不丢失。这点非常关键，因为很多时候我们容易混淆责任的边界，如果搞不清楚事情由谁负责，自然也就不知道由谁来出解决方案了。

那 Kafka 到底在什么情况下才能保证消息不丢失呢？

一句话概括，Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。

这句话里面有两个核心要素，我们一一来看。

第一个核心要素是“已提交的消息”。什么是已提交的消息？当 Kafka 的若干个 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。

那为什么是若干个 Broker 呢？这取决于你对“已提交”的定义。你可以选择只要有一个 Broker 成功保存该消息就算是已提交，也可以是令所有 Broker 都成功保存该消息才算是已提交。不论哪种情况，Kafka 只对已提交的消息做持久化保证这件事情是不变的。

第二个核心要素就是“有限度的持久化保证”，也就是说 Kafka 不可能保证在任何情况下都做到不丢失消息。举个极端点的例子，如果地球都不存在了，Kafka 还能保存任何消息吗？显然不能！倘若这种情况下你依然还想要 Kafka 不丢消息，那么只能在别的星球部署 Kafka Broker 服务器了。

现在你应该能够稍微体会出这里的“有限度”的含义了吧，其实就是说 Kafka 不丢消息是有前提条件的。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。

总结一下，Kafka 是能做到不丢失消息的，只不过这些消息必须是已提交的消息，而且还要满足一定的条件。当然，说明这件事并不是要为 Kafka 推卸责任，而是为了在出现该类问题时我们能够明确责任边界。

“消息丢失”案例

好了，理解了 Kafka 是怎样做到不丢失消息的，那接下来我带你复盘一下那些常见的“Kafka 消息丢失”案例。注意，这里可是带引号的消息丢失哦，其实有些时候我们只是冤枉了 Kafka 而已。

案例 1：生产者程序丢失数据

Producer 程序丢失消息，这应该算是被抱怨最多的数据丢失场景了。我来描述一个场景：你写了一个 Producer 应用向 Kafka 发送消息，最后发现 Kafka 没有保存，于是大骂：“Kafka 真烂，消息发送居然都能丢失，而且还不告诉我？！”如果你有过这样的经历，那么请先消消气，我们来分析下可能的原因。

目前 Kafka Producer 是异步发送消息的，也就是说如果你调用的是 producer.send(msg) 这个 API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。

这种发送方式有个有趣的名字，叫“fire and forget”，翻译一下就是“发射后不管”。这个术语原本属于导弹制导领域，后来被借鉴到计算机领域中，它的意思是，执行完一个操作后不去管它的结果是否成功。调用 producer.send(msg) 就属于典型的“fire and forget”，因此如果出现消息丢失，我们是无法知晓的。这个发送方式挺不靠谱吧，不过有些公司真的就是在使用这个 API 发送消息。

如果用这个方式，可能会有哪些因素导致消息没有发送成功呢？其实原因有很多，例如网络抖动，导致消息压根就没有发送到 Broker 端；或者消息本身不合格导致 Broker 拒绝接收（比如消息太大了，超过了 Broker 的承受能力）等。这么来看，让 Kafka“背锅”就有点冤枉它了。就像前面说过的，Kafka 不认为消息是已提交的，因此也就没有 Kafka 丢失消息这一说了。

不过，就算不是 Kafka 的“锅”，我们也要解决这个问题吧。实际上，解决此问题的方法非常简单：Producer 永远要使用带有回调通知的发送 API，也就是说不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。不要小瞧这里的 callback（回调），它能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。

举例来说，如果是因为那些瞬时错误，那么仅仅让 Producer 重试就可以了；如果是消息不合格造成的，那么可以调整消息格式后再次发送。总之，处理发送失败的责任在 Producer 端而非 Broker 端。

你可能会问，发送失败真的没可能是由 Broker 端的问题造成的吗？当然可能！如果你所有的 Broker 都宕机了，那么无论 Producer 端怎么重试都会失败的，此时你要做的是赶快处理 Broker 端的问题。但之前说的核心论据在这里依然是成立的：Kafka 依然不认为这条消息属于已提交消息，故对它不做任何持久化保证。

案例 2：消费者程序丢失数据

Consumer 端丢失数据主要体现在 Consumer 端要消费的消息不见了。Consumer 程序有个“位移”的概念，表示的是这个 Consumer 当前消费到的 Topic 分区的位置。下面这张图来自于官网，它清晰地展示了 Consumer 端的位移数据。
【03-配图-Consumer端的位移数据.png】

比如对于 Consumer A 而言，它当前的位移值就是 9；Consumer B 的位移值是 11。

这里的“位移”类似于我们看书时使用的书签，它会标记我们当前阅读了多少页，下次翻书的时候我们能直接跳到书签页继续阅读。

正确使用书签有两个步骤：第一步是读书，第二步是更新书签页。如果这两步的顺序颠倒了，就可能出现这样的场景：当前的书签页是第 90 页，我先将书签放到第 100 页上，之后开始读书。当阅读到第 95 页时，我临时有事中止了阅读。那么问题来了，当我下次直接跳到书签页阅读时，我就丢失了第 96～99 页的内容，即这些消息就丢失了。

同理，Kafka 中 Consumer 端的消息丢失就是这么一回事。要对抗这种消息丢失，办法很简单：维持先消费消息（阅读），再更新位移（书签）的顺序即可。这样就能最大限度地保证消息不丢失。

当然，这种处理方式可能带来的问题是消息的重复处理，类似于同一页书被读了很多遍，但这不属于消息丢失的情形。在专栏后面的内容中，我会跟你分享如何应对重复消费的问题。

除了上面所说的场景，其实还存在一种比较隐蔽的消息丢失场景。

我们依然以看书为例。假设你花钱从网上租借了一本共有 10 章内容的电子书，该电子书的有效阅读时间是 1 天，过期后该电子书就无法打开，但如果在 1 天之内你完成阅读就退还租金。

为了加快阅读速度，你把书中的 10 个章节分别委托给你的 10 个朋友，请他们帮你阅读，并拜托他们告诉你主旨大意。当电子书临近过期时，这 10 个人告诉你说他们读完了自己所负责的那个章节的内容，于是你放心地把该书还了回去。不料，在这 10 个人向你描述主旨大意时，你突然发现有一个人对你撒了谎，他并没有看完他负责的那个章节。那么很显然，你无法知道那一章的内容了。

对于 Kafka 而言，这就好比 Consumer 程序从 Kafka 获取到消息后开启了多个线程异步处理消息，而 Consumer 程序自动地向前更新位移。假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于 Consumer 而言实际上是丢失了。

这里的关键在于 Consumer 自动提交位移，与你没有确认书籍内容被全部读完就将书归还类似，你没有真正地确认消息是否真的被消费就“盲目”地更新了位移。

这个问题的解决方案也很简单：如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移。在这里我要提醒你一下，单个 Consumer 程序使用多线程来消费消息说起来容易，写成代码却异常困难，因为你很难正确地处理位移的更新，也就是说避免无消费消息丢失很简单，但极易出现消息被消费了多次的情况。

最佳实践

看完这两个案例之后，我来分享一下 Kafka 无消息丢失的配置，每一个其实都能对应上面提到的问题。

1。不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。
2。设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。
3。设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries > 0 的 Producer 能够自动重试消息发送，避免消息丢失。
4。设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。
5。设置 replication.factor >= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。
6。设置 min.insync.replicas > 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。
7。确保 replication.factor > min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。
8。确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。

小结

今天，我们讨论了 Kafka 无消息丢失的方方面面。我们先从什么是消息丢失开始说起，明确了 Kafka 持久化保证的责任边界，随后以这个规则为标尺衡量了一些常见的数据丢失场景，最后通过分析这些场景，我给出了 Kafka 无消息丢失的“最佳实践”。总结起来，我希望你今天能有两个收获：

明确 Kafka 持久化保证的含义和限定条件。
熟练配置 Kafka 无消息丢失参数。
【03-配图-无消息丢失配置怎么实现.jpg】

开放讨论
其实，Kafka 还有一种特别隐秘的消息丢失场景：增加主题分区。当增加主题分区后，在某段“不凑巧”的时间间隔后，Producer 先于 Consumer 感知到新增加的分区，而 Consumer 设置的是“从最新位移处”开始读取消息，因此在 Consumer 感知到新分区前，Producer 发送的这些消息就全部“丢失”了，或者说 Consumer 无法读取到这些消息。严格来说这是 Kafka 设计上的一个小缺陷，你有什么解决的办法吗？

欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。

精选留言(89)


阳明
总结里的的第二条ack=all和第六条的说明是不是有冲突
作者回复: 其实不冲突。如果ISR中只有1个副本了，acks=all也就相当于acks=1了，引入min.insync.replicas的目的就是为了做一个下限的限制：不能只满足于ISR全部写入，还要保证ISR中的写入个数不少于min.insync.replicas。
2019-06-27

5

23

lmtoo
最后一个问题，难道新增分区之后，producer先感知并发送数据，消费者后感知，消费者的offset会定位到新分区的最后一条消息？消费者没有提交offset怎么会从最后一条开始的呢？
作者回复: 如果你配置了auto.offset.reset=latest就会这样的
2019-06-27


6

cricket1981
consumer改用"从最早位置"读解决新加分区造成的问题
2019-06-27


6

曹伟雄
单个 Consumer 程序使用多线程来消费消息说起来容易，写成代码却异常困难，因为你很难正确地处理位移的更新，也就是说避免无消费消息丢失很简单，但极易出现消息被消费了多次的情况。
关于这个问题，老师能否提供个java代码的最佳实践? 谢谢!
作者回复: 写过一两篇，https://www.cnblogs.com/huxi2b/p/7089854.html，

但总觉得不太完美。如果你想深入了解的话，推荐读一下Flink Kafka Connector的源码
2019-06-30


5

杰锅不是锅
老师，我想问个问题，假如一个topic有3个partion ，我有三个消费端去消费topic，这三个消费端，是怎么去对应三个partion?曾经在线上遇到过消费太慢，导致消息重新均衡，重复消费了，有好的解决方法吗？
作者回复: 通常情况下能够保障每个consumer消费一个分区。如果消费慢，需要看到底是哪里慢？是Kafka给你消息的速度慢还是你自己处理消息的速度慢。可以适当增加max.poll.interval.ms看看
2019-07-14


4

💪😊
新建分区丢失是因为没有offset就从lastest开始读取，可以改成没有offset的时候从ealiest读取应该就可以了
2019-07-05

1

4

nightmare
多线程消费这么确保手动提交offset管理不会丢失呢，期待老师给一个消费端最佳实践
2019-06-28


4

巧克力黑
老师，你好。仔细阅读文稿后，仍有一些困惑
1、如果只用 send()方法（fire and forget）， 即使配置retries，producer也是不知道消息状态，是不会重试的。所以说配置retries，要搭配send(msg, callback)，这么理解正确么？
2、配置了retries, producer是怎么知道哪条消息发送失败了，然后重试
作者回复: 1. 不是。如果配置了retries，即使调用send(msg)也是会重试的。这是Kafka producer自己实现的机制，不需要用户干预
2. Broker发送response给producer，里面会保存error信息以及那个(些)batch出错了
2019-06-28

3

3

永光
看了评论区回答还是不太理解，第二条ack=all与第六条min.insync.replicas 怎样协调工作的，总感觉是有冲突的。
问题是：
第二条的“已提交”和第六条的“已提交”是同一个意思吗？如果是同一个意思，那定义为什么不一样呀？

作者回复: acks=all表示消息要写入所有ISR副本，但没要求ISR副本有多少个。min.insync.replicas做了这样的保证
2019-06-27

4

3

明翼
这个问题我想个办法就是程序停止再增加分区，如果不能停止那就找个通知机制了。请教一个问题min.insync.replicas这个参数如果设置成3，假设副本数设置为4，那岂不是只支持一台broker坏掉的情况？本来支持三台坏掉的，老师我理解的对不对
作者回复: 嗯嗯，是的。本来就是为了更强的消息持久化保证，只能牺牲一点高可用性了~~
2019-06-27

2

3

ban
老师，
如果我有10个副本，isr=10，然后我配置ack=all，min.insync.replicas=5，
这时候这两个参数以谁为准，生产一个消息，必须是全部副本都同步才算提交，还是只要5个副本才算提交？
作者回复: min.insync.replicas是保证下限的。acks=all的含义是producer会等ISR中所有副本都写入成功才返回，但如果不设置min.insync.replicas = 5，默认是1，那么假设ISR中只有1个副本，只要写入这个副本成功producer也算其正常写入，因此min.insync.replicas保证的写入副本的下限。
2019-08-03


2

Alan
1 外部持久化每个topic的每个消费者组的每个patition的offset。

2 程序重启时继续上一次的offset

3 监控每个partition的offset，每次的from offset和to offset是不是线性连续的消费

4 允许重复消费，在消费端去重
2019-06-28


2

QQ怪
不知道是不是可以这样，生产者感知到了有新分区加入立即通知broke端下的消费者不能消费消息，直到消费端都感应到了加入的新分区之后，生产者和消费者才继续工作
2019-06-27


2

空知
老师问下 
第7条 一个副本挂掉 整个分区不能用了 是因为每次都必须保证可用副本个数 必须跟提交时候一致 才可以正常使用,又没有冗余副本导致的嘛?
作者回复: 是因为不满足min.insync.replicas的要求了。比如该参数=2，当前ISR中只剩1个副本了，那么producer就没法生产新的消息了。
2019-06-27

1

2

没事走两步
如果consumer改用"从最早位置"读解决新加分区造成的问题，那会不会导致旧的分区里的已被消费过的消息重新全部被消费一次
作者回复: 只要位移没有越界以及有提交的位移，那么就不会出现这种场景。
2019-06-27

1

2

亮
老师好，有个问题，就是：retries 和 send里面的callback，是什么关系？因为有说retries是kafka自动重试的次数，那么还要callback干吗，callback的意义在哪里呢？ 如果一定要坚持用send(callback)api，那么retries是用来干吗的呢？ 这两者之间的关系是什么呢？谢谢。
作者回复: callback可以处理消息发送之后的逻辑，不一定就是失败的逻辑。retries是预防那种瞬时错误的，比如网络抖动这种问题，让Kafka自动重试一下会比较方便不是吗
2019-11-16


1

浪迹人生
请问消息的createTimestamp 是在生产者服务器上生成的，还是在进入不同partition 后生成的？我能不能根据这个时间戳来判断不同分区的消息原始全局顺序？谢谢🙏
作者回复: 在生产者服务器上生成的。个人感觉不可以，毕竟每个producer服务器上的时钟不是实时同步的。事实上，用时钟来保证同步性是一件非常不靠谱的事情
2019-11-01


1

知行合一
老师，课后问题会出一节课统一解答吗
2019-08-24

1

1

玉剑冰锋
老师好，针对producer为filebeat有什么是建议配置的吗？我们生产好像没有配置这方面的参数
2019-06-27


1

杰洛特
老师，请问如果配置了 retries>0，还需要在带回调的callback里显示处理可重试异常吗？还是只需处理不可重试异常就可以了？有回调的示例代码吗？
作者回复: 通常在Callback中只需要处理严重错误就可以了。回调的处理逻辑以具体场景而定，没有特定有意义的示例代码
2019-11-30



美美
胡老师 还有一种消息重复的情况希望帮忙分析下。producer发送消息后，broker成功写入消息了，但是ack因为网络问题没有到达producer，生产者可能会重试发送这条消息。
这种问题如何避免重复消费呢
作者回复: 使用幂等producer
2019-11-24



 come on 
你好胡老师，想问一下 kafka是在落地刷盘之后，同步副本成功后，才能会被消费吗？
作者回复: 其实，有可能在落盘之前就被消费了。能否被消费不是看是否flush到磁盘，而是看leader副本的高水位是否越过了该条消息
2019-11-21

1


sun
broker已经写到页缓存，此时如果broker挂了，消息算丢失吗？该怎么处理呢？
作者回复: 在这台broker上消息的确算丢失了，不过Kafka在软件层面提供了副本机制可以预防这种情况
2019-11-17



朱东旭
您好，胡夕老师，retries是否会导致消息乱序呢?
作者回复: 如果max.in.flight.requests.per.connection设置成大于0的数，那么的确有可能的。
2019-10-30



注定非凡
1：什么是不丢失
Kafka只对“已提交”的消息（committed message）做有限度持久化保证。
        A：“已提交”的定义：Kafka的若干个（可自定义配置为一个或全部）Broker成功接收到，并写入日志后即为以成功提交。
       B：有限度的持久化保证：kafka的消息不丢失的前提是N个Broker中至少有一个存活。

2：消息丢失场景
A：生产者丢失消息：
（1）：Kafka Producer是异步发送消息，使用producer.send(msg)发送消息，可以立即得到响应，但不能确定是否真的发送成功。
（2）：网络抖动，消息本身不合格都会导致Broker无法正常接收消息
解决：使用带有回调的producer.send(msg，callback)，回调可以准确的告诉我们消息是否真的发送成功。

B：消费者丢失消息：
（1）Consumer端的位移数据出现异常，导致消息被略过
解决：先消费消息，在更新位移记录（这个可能会导致重复消费问题）
（2）多个Consumer实例同时消费，但部分实例消费失败，原因是每个确认消息是否成功消费，位移数据就已经被更新。
解决：如果是多线程异步处理消费消息，consumer，程序就不要开启自动提交位移，让应用程序手动提交。

3：最佳实践
A：使用带回调通知的方法，发送消息
B：Producer端设置相关参数：
（1）设置acks=all，表示所有副本Broker都要接收到该消息，才算提交成功。
（2）设置retries>0，表示Producer能够自动重试消息发送，避免消息丢失。
C：Broker端设置相关参数：
（1）：设置unclean.leader.election.enable = false，控制Broker有资格竞选分区的leader，禁止落后原Leader的太多Broker参加竞选，避免成为新的Leader，造成消息丢失。
（2）：设置 replication.factor >=3，表示将消息多备份几份。
（3）：设置 min.insync.replicas >1，控制消息至少要被写入到多少个副本才算是“已提交”。这个设置成大于1可以提升消息持久性。生产环境不可以设置为默认值1。
（4）：设置replication.factor = min.insync.replicas + 1， 确保replication.factor>min.insync.replicas，若两者相等，那么只要有一个副本挂机，整个分区都无法正常工作。
D：Consumer端设置相关参数：
（1）设置enable.auto.commit=false，表示关闭自动提交，使用手动提交位移方式。
2019-10-28



Geek_9577e8
老师有个问题想请教下。我们公司kafka一般这么使用，我申请一个topic和一个consumergroup，写好consumer代码然后发到生产环境机器集群中。我理解每个生产环境机器都对应一个consumer？如果是这样，那生产环境消费者机器数量是不是不能超过partition数量，否则会出现多个消费者消费一个partition的情况？
作者回复: 
“每个生产环境机器都对应一个consumer” ——不一定啊

在消费者组机制下，消费者实例的数量最好不要超过分区数，否则会有消费者实例消费不到分区，但不会出现多个消费者消费一个分区的情况。

这里的实例可以位于不同的线程、进程甚至是不同的机器上。
2019-10-27



wei.li
至少一次/至多一次的语义是通过ack可retires参数配置吗？
作者回复: 在producer端是这样的，在consumer端是通过控制消费数据和提交位移的时机来实现
2019-09-26



蒙开强
老师，你好，kafka的leader副本与Follower副本之间，如果leader挂了，follower副本与leader副本落下的数据不是太大，这个时候切换follower副本选举为leader，这个时候就会有消息丢失，这么看来kafka不能保证百分之百的不丢数据。
2019-09-24



miwucc
发送端的消息持久化如何处理？比如我发的时候连续重试3次都错，这个时候这个消息还不能抛弃，或者是这个时候发送端被重启了
作者回复: 取决于你配置的retries，如果就是3，那么producer会被显式告知发送失败，你可以在回调中处理失败逻辑。
2019-09-23



miwucc
老师，消息发送没有持久化，比如发送的时候重启了，怎办保证发送的消息不丢失？只能自己做持久化？
作者回复: 不确定100%理解了你的持久化的意思。通常我们指消息保存在了broker端这件事情为持久化。如果是这样的话，你最好设置acks=all就好了
2019-09-23



miwucc
这个不丢失消息的方法还有两个问题没有解决：
1.网络问题导致客户端没有收到ack消息
2.发送端在缓存中的消息还没发出去的时候进程被杀掉了
要解决这两个问题是不是必须自己实现发送消息持久化？没收到ack就重发？
但是如果是异步重发的话又会引起消息顺序问题。
作者回复: 1. 没有收到acks，producer会重试，导致重复发送而不是丢失消息
2. 第二个问题对broker而言不是丢失消息场景，因为都没有发送到broker端。
2019-09-20



云师兄
acks=all表示消息要写入所有ISR副本，但没要求ISR副本有多少个。min.insync.replicas做了这样的保证

如果min.insync.replicas的参数设置比实际的isr副本多，producer的消息必须阻塞等broker的isr数量达到min.insync.replicas才提交成功吗
作者回复: 嗯，是的。当然如果一直不成功，最终producer请求会超时
2019-09-20



云师兄
已提交但是会丢失的情况，应该还有前面章节提到的page cache未同步到磁盘前宕机的情况吧？而这种情况不属于kafka应用的缺陷
2019-09-20



虞大胆
老师，python生产者api send方法并没有回调参数。
2019-09-17



miwucc
retries在开启batch提交的时候会导致发送顺序错乱
2019-09-16

1


英耀
胡老师您好，对于您在"最佳实践"小节第4点提到的“如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失”存在疑问。我理解分区中的数据副本之间是通过共识算法来保证一致性的，对常见的两种共识算法Raft和Paxos（不知道kafka使用的是哪一种），都不会出现上述的问题。对Raft而言，leader election时会选择log index最长的follower作为新的leader，顾不存在上述问题；Paxos而言，对于被多数派commit的日志/实例，在新leader选举的propose阶段会进行日志回放，它会询问其他节点并选择已被多数派committed的日志重新执行算法，因此即使新的leader的日志落后很多，但也不会存在日志丢失的问题，只是日志回放的时间会更长而已。不知道是不是我理解的层面或者角度跟老师您不一致，才会导致这样的疑惑，希望老师答疑。
2019-09-16



Geek_b809ff
老师，关于多线程消费的问题我一直不太明白
1、为什么自动提交会导致消息丢失，是因为自动提交不管消费者端有没有完全消费成功都会提交offset吗？
2、如果是这样的话，那么单线程的自动提交也会导致消息丢失吧，一样的道理，如果消费者端因为业务异常消费失败了，它也把offset上传了。
3、如果是这样的话，自动提交还有什么业务价值呢？
求老师解惑，谢谢
作者回复: 1. 不是，是因为每个线程无法顾忌其他线程的消费进度
2. 单线程不会的，毕竟只有一个线程嘛。
3. 自动提交简单方便，还能够自动重试
2019-08-31



安静
问个问题，为什么强调只有在多线程消费的时候要将自动提交改成手动提交，按照我的理解消费程序其实都应该将自动提交改成手动提交，这边有什么考虑吗？
作者回复: 自动提交有其应用的场景。如果你并不在乎消息重复的话，使用自动提交是很省事的做法。
2019-08-25



willmeng
胡大，您好。 broker三个节点，Kafka版本：kafka_2.12-2.3.0。我配置了#replication.factor=3，#min.insync.replicas=2，创建topic的时候能成功，用命令从写入消息也成功。但是消费的时候会报错。
kafka_2.12-2.3.0]# [2019-08-16 18:32:41,201] INFO [GroupCoordinator 1]: Member consumer-1-6524b252-55f4-4fe8-8fe9-7ab05de683b1 in group console-consumer-18018 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-16 18:32:41,202] INFO [GroupCoordinator 1]: Group console-consumer-18018 with generation 44 is now empty (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2019-08-16 18:32:41,203] ERROR [ReplicaManager broker=1] Error processing append operation on partition __consumer_offsets-29 (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.NotEnoughReplicasException: The size of the current ISR Set(1) is insufficient to satisfy the min.isr requirement of 2 for partition __consumer_offsets-29
[2019-08-16 18:32:41,203] WARN [GroupCoordinator 1]: Failed to write empty metadata for group console-consumer-18018: The coordinator is not available. (kafka.coordinator.group.GroupCoordinator)
创建topic的参数是--replication-factor 3 --partitions 3 
只要注释了这两个配置就一切正常。麻烦给提示一下问题。
作者回复: 内部主题__consumer_offsets的replication factor（rf）不够，或者说，这个主题的rf值小于offsets.topic.replication.factor值
2019-08-16

1


godtrue
当增加主题分区后，在某段“不凑巧”的时间间隔后，Producer 先于 Consumer 感知到新增加的分区，而 Consumer 设置的是“从最新位移处”开始读取消息，因此在 Consumer 感知到新分区前，Producer 发送的这些消息就全部“丢失”了，或者说 Consumer 无法读取到这些消息。
这段描述没太明白，假如现在只有一个分区0，新增了一个分区1，并且producer先感知且向这个分区写入了一个消息，在分区的开始位置0，consumer随后也感知到了，从最新位移处开始读，这个最新位移处指哪里？consumer不是从分区1的位置0消费消息的嘛？
作者回复: 最新位移就是1了，因为此时分区1的最新位移已经变更为1了
2019-08-14

2


DC
以前在callback里做过对Kafka的熔断逻辑，并且可以自动恢复熔断，防止Kafka集群问题影响应用
有一个疑问：就是看到这里发现会对kafka集群都会有一份自己的broker配置，如果我不同业务比如日志业务和订单业务可能对Kafka集群的配置需求不一样，是推荐部署两台Kafka集群吗？
作者回复: 可以设置topic级别的参数来覆盖全局参数
2019-08-05



翡冷翠
请问下设置了ack=all， retires参数可以控制哪些情况下的失败， 设置了retires还有必要再在procduer.send的回调里再次回忆失败重试吗
还有如果borker的ack响应丢失掉了， 客户端是怎么做重试的， 超过一定时间收不到ack就重新发送吗
作者回复: 只对可重试异常进行重试。
是的，收不到response自然会重试
2019-07-26



百越平民
是不是队列和主题（发布/订阅），consumer对于offset的记录方式是不一样的？
作者回复: 都是一样的
2019-07-25



燕羽阳
老师，请教一个问题，producer发送一条消息，broker正常commit，但是由于producer挂了，producer没收到响应。producer重新启动后，如何知道上次消息的发送结果?
作者回复: 无法知道了。。。
2019-07-24



非礼勿言-非礼勿听-非礼勿视
min.insync.replicas > 1这个和producer的参数ack=all，是不是只要有min.insync.replicas这些个副本同步了数据，就是all语义了
2019-07-20



野性力量
producer实例化的时候需要指定所有topic相关的leader broker的IP，那么发生重新选主，producer如何知道新主的IP并进行路由呢？
作者回复: 发送失败后会拉取最新的元数据，然后获知新的leader
2019-07-18



外星人
你好，有两个问题请教下您。
1. 我们生产上有的topic的replica是2，那min.insync.replica是不是就不适合设置为2了？
2. 我们在用flink两阶段提交时，发现，在重启broker时，任务会报错：the server is not the leader for that topic-partition，请问下是为什么啊？我看逻辑开始事务retries会设置为int.max，我们的客户端版本是011
作者回复: 1. 可以设置成2，只是任何副本就不能挂了，否则就不能用了
2. 感觉是flink对kafka leader变更没有生效导致的，和kafka关系不大
2019-07-12



james
从最早位置开始消费，如果consumer挂了重启后就消费之前数据了，broker是如何标示每个consumer的呢？k8s环境下如果不控制绑定，那么启动后就在新节点了
作者回复: Broker端上的内部主题保存了每个consumer的信息
2019-07-11



Jason_鹏
有两个问题
1、acks=all 分区副本的个数为3，producer将消息发送给Leader分区后，两个Follower分区还未同步，或者由于网络延时问题迟迟没有同步，这时消息者是否可以消费Leader分区上的这条消息，如果可以话，就会出现producer因为超时没有接收到ack，进行重发消息，那消费者就会出现重复消费的情况

2、我们正常的线上环境，对于同一个主题有多台消费者机器，比如对于主题T1，现在的情况是消费者C1消费的分区是P1，消费者C2消费的分区是P2，P1，P2是主题T1的两个分区，这时候线上的发版，消费者C1和C2都会进行重启，重启后如果C1变成消费分区P2，C2变成消费分区P1，offset是记录在消费端，那会不会照成消息丢失的情况
作者回复: 1. 不可以
2. 不会丢失，但可能会重复消费
2019-07-10

1


pain
我都是使用自动提交的。。。
2019-07-08



曹伟雄
老师，在请教个问题，因kafka不支持消费重试机制，如果在消费时处理消息失败（例如数据库约束失败或消息格式无效），如何设计一个可以重试的消费机制？ 谢谢
作者回复: 使用seek重新消费
2019-07-08



JasonK
你好，胡老师，http://kafka.apache.org 官网上的kafka的历史版本都下载不了，请问有什么好的方法嘛
作者回复: 嗯嗯，国内可能访问不了http://archive.apache.org/dist/kafka/

有的公司应该是买了合法的VPN可以访问，问问吧：）
2019-07-05

1


曹伟雄
老师，你好，有个问题请教， 开启手动提交offset场景，如果业务处理失败了（这时没有提交offset），终止操作。下次还会继续消费这条记录吗？auto.offset.reset=eaily， 如果会，消费还是处理失败（这时没有提交offset），这样是不是就死循环了，还是说kafka有机制，一条记录最多消费几次? 类似这种场景，老师有什么好的建议吗？ 谢谢!
作者回复: 要看怎么个失败了。比如fail-fast吗？如果是，consumer重启回来的确会从上次提交处继续消费；如果不是，比如你仅仅是记录了一个log，那么consumer就正常往下消费了。

还是要看你打算怎么处理失败
2019-07-04



Andy
留言中ISR是什么？
作者回复: In-Sync Replicas，这是一个副本集合，里面的所有副本都是和Leader副本保持同步的
2019-07-04



Geek_817ea4
min.insync.replicas=1,是指默认isr中只要存在一个leader副本即可吗？这个参数是指isr中副本数吧，而不是写入数据，比如我设置这个参数3，isr存在一个l和2个f，如果一个f被踢出isr就会报错，而不是写入数据。
作者回复: 不是的。如你所说replication.factor = 3，isr存在一个l和2个f。如果一个f被踢出，此时ISR副本数变成2，即使是acks=all的producer依然可以正常写入消息，因为2依然大于min.insync.replicas(1)。但如果再挂一个副本，ISR副本就变为1了 ，不大于min.insync.replicas了，此时producer不能写入数据。

min.insync.replicas和acks=all结合使用来标识是否能写入消息
2019-07-03



jacke
胡老师,关于配置参数的一些疑问.
我的理解:replication.factor是不是broker端备份的个数,min.insync.replica表示broker要达到“已提交”最少需要写入的备份的个数.就是在broker端:
一条消息写入的个数>=min.insync.replica的个数就视为“已提交” 也就是在 prodcer.send(msg, callback) 里面的callback回复提交的信息成功 疑问：callback 里面提示的“提交成功"是这样意思吗?
acks是producer的参数：
表示一条消息发给broker之后有多少个回复才是producer端视为“已提交” 疑问：是这样的吗？
下面有几个配置组合的例子
replication.factor(broker) min.insync.replica(broker) acks(producer)
 5 4 all 
 5 4 1
 5	5 3
 5 4 5 
胡老师能说下上面配置情况下，prodcer.send(msg, callback) callback对提交成功的意义吗？
一条消息提交成功在broker端和producer端应该一致的吧？
作者回复: acks只能是1或-1或0，不能指定任意个数。
“一条消息提交成功在broker端和producer端应该一致的吧？” ---- 不太明白什么意思 。。。
2019-07-03



王志杰
acks=all，那性能不是下降很厉害了？
作者回复: 嗯嗯，实际使用过程中的确延时会增加很多，主要是follower异步拉取需要花费很长的时间
2019-07-01



燃烧的M豆
最佳实践 5 这个 replication.factor 是 topic 级别的参数是可以在创建 topic 的时候带上的。
最佳实践 4 这个 unclean.leader.election.enable 应该才是 broker 级别的参数？
2019-07-01



天天向上
其实 auto.offset.reset这个配置也很重要 对于不自动提交，且忘记手动提交的场景来说 也是个困惑的因素
2019-07-01



Geek_jacky
你好，胡老师，我想每次隔10条记录进去消费一次，如果只有1个partition怎么做，如果有多个partition应该如何处理呢？个人认为可以手动在offset上进行处理，那么多个partition中的数据也只能保证每个partition中的消息间隔为10条，总感觉挺笨的，还有没有其他的办法？
作者回复: 你可以设置max.poll.records = 10，消费完了之后再提交位移。
2019-07-01



Geek_Sue
胡老师，您好，不知道您后面有没有计划针对单Consumer多线程处理的方式进行详细说明？我这边工作中恰好有这样的场景，现在是利用kafka stream来处理的，没有利用到多线程。
作者回复: Kafka Streams后台就是多线程的处理机制（Stream Thread)，而且Kafka Streams的确是推荐方案之一。
2019-07-01

1


曹伟雄
老师你好，请教个问题。关于offset，有必要外部持久化记录吗？ 出问题后查出来继续消费。你说的更新offset是怎么处理? 是直接调用它的api更新吗？ 谢谢
作者回复: 你可以选择将offset保存在外部持久化设备中，不过更常见的做法是使用consumer API保存在Kafka里面。常见的API包括commitSync和commitAsync
2019-06-30



lmtoo
我还有一个疑问，broker接收到消息直接交给操作系统的虚拟内存了，然后Producer以为是提交成功了，这个时候突然断电，那在虚拟内存里的消息不就丢了吗？不管配置什么参数，也是没法保证消息不丢失的呀，如果用kill -9 杀掉broker的进程，是不是虚拟内存里的消息也就不持久化到磁盘了？正确停止broker而又不会丢失消息的命令是什么？
作者回复: 停止broker的命令是kafka-server-stop，你说的情况的确会发生，好在Kafka提供了副本机制在软件层面上保证消息持久性。
2019-06-29



趙衍
老师好！抱歉我之前表述的不够清楚，请问老师可以贴出官方社区对增加主题分区以后Consumer无法读取到部分新消息这个问题的解决方案吗，就是您在最后的开放讨论里提出的这个问题，我想更深入地学习一下，谢谢老师！
作者回复: 坦率来说，我是希望大家一起讨论，而且这个没有绝对的解决方案。能想到的一个简单方法是让consumer端缓存订阅信息，如果发现新的订阅分区出现，手动调整位移到最开始处执行（比如consumer.seekToBeginning）
2019-06-28



在路上
如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移，这里的手动提交位移是什么意思啊，不太明白？
2019-06-28



巧克力黑
老师，你好！
producer.send(msg, callback)中callback主要用来做什么？可以用来重新发送数据么？如果可以的话，跟producer的配置retries是不是功能重复了
作者回复: 可以。retries是producer自动帮你重试。callback中你可以做一些处理之后再重试。
2019-06-27



z.l
另外想请教下，单个 Consumer 程序使用多线程来消费消息的情况下，应该怎样自动提交offest？以java客户端为例，我把消息放到一个线程池中异步处理，此时consumer也不知道线程池中的任务是否执行成功，如果用future+同步提交又会阻塞consumer线程。所以是不是用多consumer线程同步消费+同步提交的方式比较合理？？
2019-06-27



z.l
在“producer.send(msg, callback)的callback方法中重试，和设置retries参数重试，会不会冲突？2个都设置以哪个为准？
作者回复: 不冲突。对于可重试的错误，retries才会触发，否则直接 进入到callback
2019-06-27



guoyinbo2019
胡老师，我有以下两个疑问
一、关于最佳实践
2、设置ack=all，这里的all指的任一时刻下所有存活的follower 么?比如开始follower=3，当有一台副本挂掉是，ack=all意味着follower=2
5、 replication.factor >= 3，设置副本个数吧，如果由于副本所在broker挂了，这个参数检测会自动减少么？
例如：设置replication.factor = 3，有3台broker，若有一台broker挂了，kafka会如何处理，会按照replication.factor = 2进行同步数据么， 还是当发现副本数< replication.factor的时候就不能正常工作， 还是其他什么策略呢？
6、min.insync.replicas > 1 这个会和上面参数矛盾么
以上几个 参数都参与的“已提交”的定义，当参数不能全部满足的时候，这个“已提交”是怎么定义的呢，
各参数在“已提交”定义中是否有优先级呢，如有，优先级是什么呢？
二、关于单consumer，多线程消费问题
对于老师说的“避免无消费消息丢失很简单，但极易出现消息被消费了多次的情况。”有些不理解
我认为单consumer，多线程消费时候容易产生消息丢失
例如一个consumer2个线程，thread1消费offset=1 消息，thread2消费offset=2 消息，thread2很快处理完了消息并成功提交了offset, 但是thread1由于某种原因处理失败了，此时offset=1 的消息对于consumer来说就丢了。
不知道理解的对不对，还请老师解答。
作者回复: 1、replication.factor用于确定副本数。该参数本身不会减少。#ISR < replication.factor时也是可以正常工作的，只要#ISR >= min.insync.replicas即可。
2、min.insync.replicas限定了最少要写入ISR副本的个数，它 和acks=all不矛盾。
3、嗯嗯，差不多。关键是这种情况下我们到底应该提交哪个位移合适？提交1，那么offset=2的消息有可能重试；提交2，那么offset=1的消息可能丢失。
2019-06-27



Geek_986289
设置 acks = all。表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。如果所有的Broker都要收到消息才能算作已提交，会不会对系统的吞吐量影响很大？另外这里的副本指的是不是仅仅是ISR?
作者回复: 就我碰到的实际场景，影响还是很大的。acks=all时，大部分的请求处理延时都花在了follower同步上。

是的，acks=all表明所有ISR中的副本都要同步。
2019-06-27



Xiao
胡老师，broker在持久化的时候理论上也存在数据丢失的情况吧。
2019-06-27



振超
设置从最新 offset 处开始消费，实际上默认就接受允许丢失一部分消息，这应该不算是缺陷
作者回复: 嗯嗯，但从用户的角度而言，我在producer无宕机的情形下增加了分区，producer正常生产的消息不应该不能被消费，对吧？
2019-06-27

1


张庆
胡夕大拿 您好，关于消费者数据丢失的第一种情况，我不是很明白，在什么情况下读书和更新书签的顺序是颠倒的啊？我理解的如果设置为自动提交了，就是定时间隔的位移提交，在这个间隔时间里面，如果正在消费数据，此时宕机了，还没有提交位移，如果重启了，可能会出现重复消费。不理解消息丢失的场景是什么样子的？您能详细解释一下吗？
作者回复: 自动提交不会出现这个问题。主要是针对手动提交哦。而且这里的消费其实指的是你执行真正的消息处理逻辑，而不是指从kafka中获取消息。

Kafka默认提供至少一次语义。设想如果你想实现最多一次处理语义怎么做？就是要先提交位移，再处理消息。对吧？
2019-06-27



Icedmaze
目前想到的方法有两种
一种是在消费端初始化的时候配置“从新位移处开始消费”，当各个分区记录了位移信息后，再将配置改为“从最早位移处开始消费”策略，利用已产生了标志位的分区不受消费策略影响的特性，保证在之后的业务中，新增分区都不会产生“丢失”问题。
第二种方法是当新增分区后，利用消费端会产生rebalance事件的特性，可以在rebalance的时候判断该分区有无消费位移，如果无位移位，则强制将位移位设置为0从头开始消费。（该方法纯属猜测）
2019-06-27

1


趙衍
老师可以贴出官方社区对这个问题的解答吗，我想更深入地了解一下这个问题
作者回复: 哪个问题？
2019-06-27



刚子
broker的配置、producer和consumer的配置如此多和复杂，不容易记忆。需要后期根据业务需求进行相应调整，是否有模版的配置参数或者自感应的功能，可以帮助开发和运维快速正确的使用Kafka
2019-06-27



13761642169
如果消息是随机发送，对于消费者来说，可以使用暂停消费，新分区有消息进来和消费实例注册新分区完成，启用消费。这是我认为的想法
2019-06-27



没事走两步
改用"从最早位置"读，又会导致什么问题
2019-06-27



13761642169
其实很好解决，在发送端用分区hash一个分区key，指定分区发送，增加分区之后，在确保kafka消费者实例注册上新分区后，将发送端重启。
2019-06-27



刘朋
思考讨论:
在业务场景允许暂停的的情况下,在增加主题分区前,先暂停Producer端的写入;然后增加主题分区;其次重启或等待Consumer端;最后启动Producer端.

在业务场景不允暂停的情况下,需要有个地方(redis/zookeeper)缓存一个配置信息.里面分别记录Producer端和Consumer端 主题分区信息.

比如，Producer topic_partitions: M ,Consumper topic_partitions: N

Producer端每次消费消息前,
首先,会判断Topic的分区数,如果有变更,会及时更新 Producer topic_partitions: M
其次,会判断 M 是否等于 N.
如果 M = N,则写入数据;
如果 M > N,则循环等待,不写入数据;
如果 M < N,则会更新配置文件(Producer topic_partitions:N),然后写入数据

Consumper端每次消费消息前,会判断Topic的分区数,如果有变更,会及时更新 Consumper topic_partitions: N

缺点,可能会增加一定的检测时长.是否增加此检测步骤后会影响到业务提交/消费需要根据业务特性进行压测检验.
2019-06-27



dream
broker端的asks=all虽然保证了无消息丢失的实现，但是会使broker响应producer的时间变长吧...
作者回复: 是的。实际场景中非常明显。。。
2019-06-27

1


风中花
刚收到推送就这么多留言啦！厉害了我的哥们
2019-06-27



杨俊
如果是flume组件对接kafka，producer端参数应该设置不了这么全吧
作者回复: 也可以的，flume kafka sink也有对应的参数设置方法
2019-06-27



黑崽
好问题.很多人没有意识到这个问题，解决方案两种，一个是从最老消费者，另外可以rebalance时候做。由从最老消费在首次启动可能导致pagecache in/out增多，吞吐下降，所以我们选择在rebalance时候做
2019-06-27



mini希
是否可以每次往前读一次，最新位移-1，看是否消费过了
2019-06-27



我自成魔
老师，ack是不是针对的broker级别，而min.insync.replica 针对的是分区下的副本？
作者回复: 它们都是帮助提升消息持久化程度用的
2019-06-27



＼（－－）／未来的首席架构师
设置成ack=all，还会出现第四条的场景吗？消息还会落后？？？？？？
作者回复: 可能的。acks=all表示要等待ISR中的副本全部写入成功，非ISR的副本依然可能落后leader
2019-06-27



Leon📷
增加新的分区的时候让消费的给生产者发一个确认，生产者收到确认之后才会向新的分区里面写数据。
2019-06-27



没事走两步
老师，最后一段新增分区导致消息全部丢失，这个不是很明白
作者回复: 新增加了分区之后consumer和producer不会立即感知，通常可能会等待一段时间。如果producer先感知到了并向新分区发送消息，那么consumer后感知到之后直接从最新位移开始读取消息，那么之前发送的消息就不会被消费了。
2019-06-27

4




