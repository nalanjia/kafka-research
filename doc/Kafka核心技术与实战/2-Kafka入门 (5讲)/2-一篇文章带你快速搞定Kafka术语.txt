你好，我是胡夕。今天我们正式开启 Apache Kafka 学习之旅。

在 Kafka 的世界中有很多概念和术语是需要你提前理解并熟练掌握的，这对于后面你深入学习 Kafka 各种功能和特性将大有裨益。下面我来盘点一下 Kafka 的各种术语。

在专栏的第一期我说过 Kafka 属于分布式的消息引擎系统，它的主要功能是提供一套完备的消息发布与订阅解决方案。在 Kafka 中，发布订阅的对象是主题（Topic），你可以为每个业务、每个应用甚至是每类数据都创建专属的主题。

向主题发布消息的客户端应用程序称为生产者（Producer），生产者程序通常持续不断地向一个或多个主题发送消息，而订阅这些主题消息的客户端应用程序就被称为消费者（Consumer）。和生产者类似，消费者也能够同时订阅多个主题的消息。我们把生产者和消费者统称为客户端（Clients）。你可以同时运行多个生产者和消费者实例，这些实例会不断地向 Kafka 集群中的多个主题生产和消费消息。

有客户端自然也就有服务器端。Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一。

实现高可用的另一个手段就是备份机制（Replication）。备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在 Kafka 中被称为副本（Replica）。好吧，其实在整个分布式系统里好像都叫这个名字。副本的数量是可以配置的，这些副本保存着相同的数据，但却有不同的角色和作用。Kafka 定义了两类副本：领导者副本（Leader Replica）和追随者副本（Follower Replica）。前者对外提供服务，这里的对外指的是与客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互。当然了，你可能知道在很多其他系统中追随者副本是可以对外提供服务的，比如 MySQL 的从库是可以处理读操作的，但是在 Kafka 中追随者副本不会对外提供服务。对了，一个有意思的事情是现在已经不提倡使用 Master-Slave 来指代这种主从关系了，毕竟 Slave 有奴隶的意思，在美国这种严禁种族歧视的国度，这种表述有点政治不正确了，所以目前大部分的系统都改成 Leader-Follower 了。

副本的工作机制也很简单：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。

虽然有了副本机制可以保证数据的持久化或消息不丢失，但没有解决伸缩性的问题。伸缩性即所谓的 Scalability，是分布式系统中非常重要且必须要谨慎对待的问题。什么是伸缩性呢？我们拿副本来说，虽然现在有了领导者副本和追随者副本，但倘若领导者副本积累了太多的数据以至于单台 Broker 机器都无法容纳了，此时应该怎么办呢？一个很自然的想法就是，能否把数据分割成多份保存在不同的 Broker 上？如果你就是这么想的，那么恭喜你，Kafka 就是这么设计的。

这种机制就是所谓的分区（Partitioning）。如果你了解其他分布式系统，你可能听说过分片、分区域等提法，比如 MongoDB 和 Elasticsearch 中的 Sharding、HBase 中的 Region，其实它们都是相同的原理，只是 Partitioning 是最标准的名称。

Kafka 中的分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，这条消息要么在分区 0 中，要么在分区 1 中。如你所见，Kafka 的分区编号是从 0 开始的，如果 Topic 有 100 个分区，那么它们的分区号就是从 0 到 99。

讲到这里，你可能有这样的疑问：刚才提到的副本如何与这里的分区联系在一起呢？实际上，副本是在分区这个层级定义的。每个分区下可以配置若干个副本，其中只能有 1 个领导者副本和 N-1 个追随者副本。生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。分区位移总是从 0 开始，假设一个生产者向一个空分区写入了 10 条消息，那么这 10 条消息的位移依次是 0、1、2、…、9。

至此我们能够完整地串联起 Kafka 的三层消息架构：

第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。
第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。
第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。
最后，客户端程序只能与分区的领导者副本进行交互。

讲完了消息层次，我们来说说 Kafka Broker 是如何持久化数据的。总的来说，Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此 Kafka 必然要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。

这里再重点说说消费者。在专栏的第一期中我提到过两种消息模型，即点对点模型（Peer to Peer，P2P）和发布订阅模型。这里面的点对点指的是同一条消息只能被下游的一个消费者消费，其他消费者则不能染指。在 Kafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。为什么要引入消费者组呢？主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。我会在专栏的后面详细介绍消费者组机制，所以现在你只需要了解消费者组是做什么的即可。另外这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。

消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。嗯，其实既是大名鼎鼎，也是臭名昭著，因为由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。

每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。注意，这和上面所说的位移完全不是一个概念。上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，毕竟它是消费者消费进度的指示器嘛。另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。我个人把消息在分区中的位移称为分区位移，而把消费者端的位移称为消费者位移。

小结

我来总结一下今天提到的所有名词术语：

消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。
主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。
分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。
消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。
生产者：Producer。向主题发布新消息的应用程序。
消费者：Consumer。从主题订阅新消息的应用程序。
消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。
消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。
最后我用一张图来展示上面提到的这些概念，希望这张图能够帮助你形象化地理解所有这些概念：
【2-配图-概念.png】

开放讨论

请思考一下为什么 Kafka 不像 MySQL 那样允许追随者副本对外提供读服务？
欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。

精选留言(132)


huxi_2b 置顶
结尾处增加了一张图，提炼了02中讲到的Kafka概念和术语，希望能够帮助到你：）
2019-06-11

2

32

明翼
看了不少留言，大有裨益，算是总结。不从follower读几个原因：1，kafka的分区已经让读是从多个broker读从而负载均衡，不是MySQL的主从，压力都在主上；2，kafka保存的数据和数据库的性质有实质的区别就是数据具有消费的概念，是流数据，kafka是消息队列，所以消费需要位移，而数据库是实体数据不存在这个概念，如果从kafka的follower读，消费端offset控制更复杂；3，生产者来说，kafka可以通过配置来控制是否等待follower对消息确认的，如果从上面读，也需要所有的follower都确认了才可以回复生产者，造成性能下降，如果follower出问题了也不好处理
2019-06-06

5

65

we
老师 这个结构，为什么不用图表示。
2019-06-06


64

时光剪影
整理一遍个人的理解：

Kafka体系架构=M个producer +N个broker +K个consumer+ZK集群

producer:生产者

Broker：服务代理节点，Kafka服务实例。
n个组成一个Kafka集群，通常一台机器部署一个Kafka实例，一个实例挂了其他实例仍可以使用，体现了高可用

consumer：消费者
消费topic 的消息， 一个topic 可以让若干个consumer消费，若干个consumer组成一个 consumer group ，一条消息只能被consumer group 中一个consumer消费，若干个partition 被若干个consumer 同时消费，达到消费者高吞吐量

topic ：主题

partition： 一个topic 可以拥有若干个partition（从 0 开始标识partition ），分布在不同的broker 上， 实现发布与订阅时负载均衡。producer 通过自定义的规则将消息发送到对应topic 下某个partition，以offset标识一条消息在一个partition的唯一性。
一个partition拥有多个replica，提高容灾能力。 
replica 包含两种类型：leader 副本、follower副本，
leader副本负责读写请求，follower 副本负责同步leader副本消息，通过副本选举实现故障转移。
partition在机器磁盘上以log 体现，采用顺序追加日志的方式添加新消息、实现高吞吐量
作者回复: 厉害！感觉比我写的简洁：）
2019-06-16

5

32

邋遢的流浪剑客
如果允许follower副本对外提供读服务（主写从读），首先会存在数据一致性的问题，消息从主节点同步到从节点需要时间，可能造成主从节点的数据不一致。主写从读无非就是为了减轻leader节点的压力，将读请求的负载均衡到follower节点，如果Kafka的分区相对均匀地分散到各个broker上，同样可以达到负载均衡的效果，没必要刻意实现主写从读增加代码实现的复杂程度
作者回复: 是的。前些天在知乎上就这个问题也解答了一下，有兴趣可以看看：https://www.zhihu.com/question/327925275/answer/705690755
2019-06-06

1

28

骨汤鸡蛋面
建议在文章中使用topic、consumer 等代替 主题、消费者实例等表述，对了解kafka的人来说，更自然一点
作者回复: 嗯嗯，好的：）
2019-06-06


18

永光
为什么 Kafka 不像 MySQL 那样允许追随者副本对外提供读服务？

答：因为mysql一般部署在不同的机器上一台机器读写会遇到瓶颈，Kafka中的领导者副本一般均匀分布在不同的broker中，已经起到了负载的作用。即：同一个topic的已经通过分区的形式负载到不同的broker上了，读写的时候针对的领导者副本，但是量相比mysql一个还实例少太多，个人觉得没有必要在提供度读服务了。（如果量大还可以使用更多的副本，让每一个副本本身都不太大）不知道这样理解对不对?
作者回复: 我个人觉得是很不错的答案，自己也学到了一些：）
2019-06-10


15

莫道不销魂
老师，我想问下
1、 kafka是按照什么规则将消息划分到各个分区的？
2、既然同一个topic下的消息分布在不同的分区，那是什么机制将topic、partition、record关联或者说管理起来的？
作者回复: 1. 如果producer指定了要发送的目标分区，消息自然是去到那个分区；否则就按照producer端参数partitioner.class指定的分区策略来定；如果你没有指定过partitioner.class，那么默认的规则是：看消息是否有key，如果有则计算key的murmur2哈希值%topic分区数；如果没有key，按照轮询的方式确定分区。
2. 这个层级其实是逻辑概念。在物理上还是以日志段（log segment）文件的方式保存，日志段文件在内存中有对应的Java对象，里面关联了你说的这些。
2019-06-11

1

9

jacke
胡老师：
       还想问个分区的问题，比如一个topic分为0，1，2 个分区
       写入0到9条消息，按照轮训分布:
              0分区：0，1，2，9
              1分区：3，4，5，
              2分区：6，7，8
        那对于消费端来说，不管是p2p点对点模式，还是push/sub模式来说，
        如何保证消费端的读取顺序也是从0到9？因为0到9条消息是分布在3个
        分区上的，同时消费者是主动轮训模式去读分区数据的，
        有没有可能读到后面写的数据呢？比如先读到5在读到4？
        ps:刚开始学习，问题比较多，谅解
    
作者回复: 目前Kafka的设计中多个分区的话无法保证全局的消息顺序。如果一定要实现全局的消息顺序，只能单分区
2019-06-22

1

8

(´田ω田`)
1、主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。
2、假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。

意思是1个分区只能同时被1个消费者消费，但是1个消费者能同时消费多个分区是吗？那1个消费者里面就会有多个消费者位移变量？
如果1个主题有2个分区，消费者组有3个消费者，那至少有1个消费者闲置？
作者回复: 在一个消费者组下，一个分区只能被一个消费者消费，但一个消费者可能被分配多个分区，因而在提交位移时也就能提交多个分区的位移。

针对你说的第二种情况，答案是：是的。有一个消费者将无法分配到任何分区，处于idle状态。
2019-06-06


7

然行
kafka客户端读操作是会移动broker中分区的offset，如果副本提供读服务，副本更变offset，再回同步领导副本，数据一致性就无法得到保障
2019-06-06

1

6

ban
老师 这个结构，为什么不用图表示。
2019-06-08


5

dbo
Myaql中从追随者读取数据对server和client都没有影响，而Kafka中从追随者读取消息意味着消费了数据，需要标记该数据被消费了，涉及到做一些进度维护的操作，多个消费实例做这些操作复杂性比较高，如果可以从追随者读也可能会牺牲性能，这是我的理解，请老师指正。
作者回复: 我个人认为维护成本不高。Kafka中消费进度由clients端来操作，即消费者来决定什么时候提交位移，而且是提交到专属的topic上，与副本本身关联不大。实际上社区最近正在讨论是否允许follower副本提供读服务。不过我同意的是，follower副本提供读服务后会推高follower所在broker的磁盘读IO
2019-06-06

1

4

巧克力黑
老师，你好
假如只有一个Producer进程，Kafka只有一分区。Producer按照1，2，3，4，5的顺序发送消息，Kafka这个唯一分区收到消息一定是1，2，3，4，5么？ Producer端，网络，数据格式等因素，会不会导致Kafka只有一个分区接收到数据顺序跟Producer发送数据顺序不一致
作者回复: 如果retries>0并且max.in.flight.requests.per.connection>1有可能出现消息乱序的情况
2019-07-02


3

趙衍
我之前在学习Kafka的时候也有过这个问题，为什么Kafka不支持读写分离，让从节点对外提供读服务？
其实读写分离的本质是为了对读请求进行负载均衡，但是在Kafka中，一个topic的多个Prtition天然就被分散到了不同的broker服务器上，这种架构本身就解决了负载均衡地问题。也就是说，Kafka的设计从一刻开始就考虑到了分布式的问题，我觉得这是Linkedln开发团队了不起的地方。
尽管如此，我觉得还有一个问题我没有想明白，如果Producer就是对某些broker中的leader副本进行大量的写入，或者Consumer就是对某些broker中的leader副本进行大量的拉取操作，那单台broker服务器的性能不还是成为了整个集群的瓶颈？请问老师，这种情况Kafka是怎么解决的呢？
作者回复: 只能是分散负载了，多做一些分区。
2019-06-07


3

QQ怪
kafka能否做到多个消费者消费一个生产者生产的数据，并能保证每个消费者消费的消息不会重复，做到并行消费?
作者回复: Kafka提供了消费者组实现你说的这个需求~~
2019-06-06


3

Mick
老师，同一主题下的分区有没有可能到不同的borker上？同一分区的副本有没有可能在不同的borker上
作者回复: “同一主题下的分区有没有可能到不同的borker上？” ——非常可能，而且也是期望的结果。

“同一分区的副本有没有可能在不同的borker上” —— 必须如此。同一分区的不同副本必然在不同的broker上。
2019-07-06


2

莫道不销魂
老师 ，一个分区的N个副本是在同个Broker中的吗，还是在不同的Broker中，还是说是随机的？
作者回复: 一个分区的N个副本一定在N个不同的Broker上。
2019-07-02

1

2

sljoai
老师，请问一下影响KafkaConsumer.poll能否读取出数据的因素有哪些呢？
场景：使用assign的方式获取数据，且poll的超时时间设置成1s。
1.消息本身较大时，当将max.partition.fetch.bytes设置成52428800（50MB）时无法读取出数据；当将max.partition.fetch.bytes变小些时，比如10M，就可以读取出数据。
2.消息本身较小时，max.partition.fetch.bytes为50MB时，也能读取出数据；
作者回复: 取不出数据时，有什么报错吗？另外你的fetch.max.bytes值多少？
2019-06-11


2

大番茄
首次接触kafka，有个理解疑问麻烦解惑：
    在：刚才提到的副本如何与这里的分区联系在 ，生产者向分区写入消息， 这个消息是和副本之间是种什么关系的啊？

另外，这个关系老师可以出张图表示吗，感谢！
 
 
作者回复: 就像专栏里面说的，副本是在分区层级下定义的，即一个分区能够配置多个副本。生产者向分区写消息时其实是向leader副本写消息。其他follower副本主动去leader副本拉取这条消息实现同步。不知道这么解释清楚点了吗
2019-06-06


2

石妖
课后问题，我觉得是以下两个原因：
1.数据库中数据的读取只是数据的展示，而kafka中消息的读取意味着消费，consumer offset就会随之增加，kafka中的读取“相当于”MySQL中的更新，这两者的逻辑是不同的；
2.kafka集群可以通过增加partition及broker的方式实现负载均衡，并不需要从follower replica读取（消费）消息，那样会增加维护consumer offset的难度；而由于第一点的差异，使得MySQL可以通过将follower数据对外提供服务的方式来减轻leader节点的压力，实现读写分离，从而达到负载均衡。
2019-06-06


2

Ryoma
老师说点对点的实现方式通过消费组，但是如果多个消费组订阅了同一个 topic ，是不是同一个消息依然会被多个消费组的消费者去消费？
作者回复: 是的。消费者组之间没有关联
2019-10-25


1

Eric
leader 副本 和 follower 副本 ，会在同一个分区么？应该在不同的分区吧，我理解有几个数据副本，就应该有几个分区，一个是leader，其他是follower，不然都在一个分区，对高可用没意义呀。。。
作者回复: 同一个分区下分leader副本和follower副本。所有的副本都是指在同一个分区下的。leader和follower位于不同的broker，实现高可用
2019-10-19


1

未未的未来
术语还是挺多的，感觉得用白板画一下，加深下印象和理解。感谢老师。
2019-10-16


1

云师兄
分区数量一开始定义后，后面可以增加分区后，原来分区的数据应该不会迁移吧？分区数量可以减少吗？
作者回复: 不会自动迁移，需要你手动迁移。分区数不可以减少
2019-09-11


1

海罗沃德
如何可以清空一個已有的topic中的所有舊的record，除了刪除topic重新創建之外有沒有其他方式？
作者回复: 可以删除topic中的记录，不过是以offset的维度。所以你要先定义哪些offset之前的消息是旧消息
2019-09-11

1

1

蚊子
请教一下老师：high water mark怎么理解？
作者回复: 在Kafka中你可以认为一个分区的HW表征了当前该分区下所有副本都已经保存了的消息的最大位移
2019-09-03

1

1

godtrue
Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一。
再次请教几个小问题：
1：启动一个kafka程序，就是启动一个broker进程服务嘛？
2：假设有三台服务器A/B/C，三个broker进程服务1/2/3，老师的建议是将1/2/3三个broker进程同时分别放在A/B/C三台机器上吗？还有不同的broker是什么概念？他们应该都是同样的kafka程序，启动后进程号会不一样，这里的不同的broker是以什么角度讲的？
初学，感觉这个broker的意思没弄明白，望老师或其它同学帮忙解答一下。
作者回复: 1. Kafka程序的含义比较模糊，它也可能指Kafka客户端程序，如果是客户端，就不是Broker进程了。Broker是服务器端的概念
2. 通常还是建议将不同的Broker放在不同的机器上。所谓不同，也就是指server.properties中的配置不同，比如每个Broker的broker.id必须是唯一的。
2019-08-13


1

蓝魔丶
老师，kafka采用多个多个分区支持负载均衡，这样无法保证全局顺序唯一吧，现在业内常采用单分区来解决这个问题，但是这样又丢失了负载均衡能力，后面kafka会针对这个问题会进一步加强吗？
作者回复: 没有。不光Kafka，所有partitioned database都有这个问题。
2019-08-03


1

小名叫大明
虽然很多大神都已经详细的回答了老师课后留的问题，但还是记录一下在没有看留言区内容时自己想到的答案。 

kafka之所以没有考虑 从副本 对外提供服务还是因为基于一致性维护成本的考虑 

留言区得到的更具体的有: 

1. 一致性的考虑
2. kafka的消息分区及主副本已经实现了类似于MySQL主节点需要从节点支持读要解决的问题: 主节点写及读压力
3. 其他
2019-07-04


1

funnyx
胡老师，您好，最近正在学习Kafka，看了您的文章，感觉获益匪浅，但是有个地方还请指教一下，在Kafka官网看的，”Each partition has one server which acts as the "leader" and zero or more servers which act as "followers". 请问这里的server该作何理解？
作者回复: server = Broker
2019-07-02


1

beiliu
老师，您好，那我想问一下，怎么使用自带带shell脚本获取到某个topic的当前最新的offset位置呀
作者回复: 专栏后面会有介绍。不过你要是着急的话，不妨试试：
bin/kafka-run-class.sh kafka.tools.GetOffsetShell 
命令
2019-06-26

1

1

jacke
胡老师问几个问题：
第一个：
每个主题划分成多个分区（Partition), 每个分区有多个备份，但是生产者生产的每条消息只会被发送到一个分区中，那其他没有使用的分区有什么用？
还有在回答去，副本在broker上的分配策略相关的：

“如果ISR为空，看是否开启了unclean leader选举，如果没有开启，那么Kafka干脆就不选leader了，直接将分区置于不可用状态；”
分区不可用，这样的情况下，是不是分区上所有的主题都不能读写了？
第二个：
      多个消费者可以消费同一个主题，那消费者自己的offset，是不是保存在client端？
作者回复: 第一，我们不可能只选择往一个分区发送消息吧。

第二，分区是在主题之下的，分区不可用了表示clients无法访问这个主题下的分区了。

第三，offset保存在broker端的内部topic中，不是在clients中保存。
2019-06-21


1

范瑞
主写从读无非就是为了减轻leader节点的压力，而kafka中数据分布相对比较均匀，所说的Follower从节点,实际上也是其他topic partition的Leader节点，所以在Follower可以读数据，那么会影响Follower节点上的做为Leader的partition的读性能，所以整体性能并没有提升，但是带来了主从数据同步延迟导致的数据不一致的问题
作者回复: 同意：）
2019-06-20


1

永光
老师你好，每个消费者有着自己的消费者位移。“重平衡”时Kafka怎么知道已挂的消费者消费到哪里了？谢谢
作者回复: 重平衡时每个消费者都会尽力去做一次位移提交（如果它会提交位移的话），这样当rebalance完成后Kafka会告诉它们订阅分区当前消费到了那里。
2019-06-10


1

永光
老师你好，
有两个疑问：
1、文中说的Leader-Follower 指的是副本之间的关系，broker之间是对等关系，对吧？如果是对等关系，生产和消费时我怎么找到领导者副本所在的broker呢？
2、希望老师大致描述一下生产和消费时Kafka内部的处理流程？（如果能画个图,那将感激不尽）
谢谢老师。
作者回复: 1. 客户端会首先请求topic分区的leader副本在哪个broker上，内部自动执行的，你无需操心；
2. 记下了你的建议，后面我会注意的。另外专栏后面关于客户端运行机制的介绍：）
2019-06-10


1

永光
老师你好，

副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。

“副本是在分区层级下的”感觉这么说不太准确，副本应该是分区的拷贝，和分区应该属于同一层级。

作者回复: 我个人觉得只要有助于正确理解Kafka，具体的说法并不是那么重要。"副本是在分区层级下的"的依据是在Kafka的源码Partition.scala中，每个分区对象都保存了一个hashmap，map中的对象就是Replica副本对象。
2019-06-10


1

huaweichen
和一些朋友讨论了一下：
1. 首先Partition已经承担了Master-Slave的“高性能”功效。
2. Follower的设计和存在，是为了“高可用”的目的，所以“高性能”的重担不在它的肩上。
3. Leader是source of truth，所以读写都应该在leader上。
4. 由于有__consumer_offsets的机制，每次读写都应该是在leader上，如果replica也参与了read服务，那么consumer offet就乱了。

不知道对不对。

老师，答案会公布在哪里啊？
作者回复: 很多问题都是开放式的，没有具体的答案。主要是想让大家一起思考一下。正确与否不重要，关键是能够参与到讨论：）

你说的我是赞同的
2019-06-07


1

双叶
Follower 不提供服务我认为是必要性不大吧，性能已经满足要求的情况下，follower 提供服务只会提高复杂度。为什么 kafka 性能满足高而 mysql 不行，除了做了分区以外，还有 kafka 读写都基本上是顺序的，I/O 压力小，计算相比数据库感觉也不复杂，所以就性能高呗。
2019-06-06


1

高志强
老师我有个问题，消费者位移可以手动往回调么，当位移向前后，分区里之前的数据还会存在么，如果存在啥时会被删除呢
2019-12-05



Feliz city
”一个很自然的想法就是，能否把数据分割成多份保存在不同的 Broker 上？...这种机制就是所谓的分区”感觉描述的不太准确，还好看了最后的图懂了
2019-11-27



百里
文字学习还是没有视频学习来得直接高效呀.
2019-11-18



 come on 
副本分区不同的broke上面吗？
作者回复: 同一个分区的多个副本一定分布在不同的Broker上
2019-11-14



KK
有一个概念容易被混淆：实现高可用的另一个手段就是备份机制（Replication），既然是备份，应该就是备用的意思，不对外提供服务。但分区中却存在两个概念，Leader副本和Follower副本，Leader副本对外提供服务，Follower副本不对外提供服务，都是副本，都是备份，为什么还都提供服务呢？与“备用”这个概念容易理解混淆
作者回复: hmmm..... 我们姑且认为Replica是广义的概念吧：） 不用纠结于这么的严格概念定义
2019-11-10



James
留言中的高手真多且问题问得特别棒
2019-11-07



懒懒的龟
消息位移和消费者位移都是一个固定的值吗，还是一个范围值。
作者回复: 它们都是值
2019-11-03



Geek_9577e8
老师我想问下
若干个partition 被同一个group中若干个consumer 同时消费，达到消费者高吞吐量。
是否一个consumer可以消费多个partition的数据(我觉得这样是没问题的)？那是否一个partition可以被同一个group中的多个consumer消费(我觉得如果是这样是有问题的，因为每个Consumer都有自己的Consumer Offset，就会出现同一条数据被多个consumer消费)？
作者回复: "是否一个consumer可以消费多个partition的数据" --- 可以的
“是否一个partition可以被同一个group中的多个consumer消费” --- 不可以的，只能被组内的一个consumer实例消费
2019-10-23

1


jacket
老师，从这一讲里，没法看出follower副本的实际作用，如果说能提高数据可靠性的话，具体体现在哪些地方呢？kafka会在什么时候使用这些follower副本？
作者回复: follower副本会不停地同步leader副本的消息，当leader副本挂掉后，follower副本就派上用场了，Kafka从ISR的follower副本中选择一个出来当新的leader
2019-10-07



飞天大白菜
主从模式follower注定是有延迟的。如果跑一个完美的consensus算法可以保证同步，但是对于kafka这样一个低延迟的服务来说可能是太过奢侈了（？）时间上来看同一个dc中的raft不慢，但是每条log也要数毫秒的时间来进行共识确认。

从follower读本质上也是一个共识问题，master和follower都要就同一个consumer的offset达成共识，是否能既保证正确性又保证低延迟大概是需要工程实践来验证的。
2019-09-25



张三丰
副本和消息是什么关系？
是一个消息有多个备份？
消费者只消费其中一个消息，其余的都是备份？
作者回复: 消息是保存在副本中的。每条消息可以保存在多个副本中实现冗余。消费者只能读取领导者副本中的消息，其他副本只是充当leader的备选而已
2019-09-23



肥low
纠正两个地方,不知道我说的准不准确:

1、为什么要引入消费者组呢？主要是为了提升消费者端的吞吐量
这个吞吐量应该是由分区(队列)和消费者的数量决定的,理论上应该保持分区数量和消费者数量一致,而不是说多个消费者争夺一个队列的情况,这种在消费组内是允许的但是并不能解决性能的问题,因为队列角度讲,消息还是一个一个的严格按照队列顺序来消费的

2、每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset)
应该是每个消费组对应到每个分区上有个最新的消费位置,而不是消费者

如果我理解的有误,请及时纠正我,谢谢
作者回复: 不用太客气。
1、感觉没什么问题
2、消费者是广义的，因为还存在standalone consumer
2019-09-23

2


肥low
因为分区(队列)是传统的队列模式,是保证消息严格顺序的保障,分区副本主要是为了保障高可用,跟MySQL的Slave场景不一样?
2019-09-23



jc9090kkk
回答问题：mysql的从库提供读机制，主要是因为mysql上存储的数据可以重复读，并且没有所谓的位移值offset的概念，所以能够保证数据一致性，而kafka的中消费过的数据需要通过offset来做标记，如果follower提供读，那必须然需要同步offset的变更，有可能就会导致数据不一致的问题，同时也会造成性能损耗。

看了这篇文章有几个疑惑的点，希望能得到老师的回复：
1.之前在网上看到过kafka中有机架的这个概念，机架的这个概念应该如何理解？
2.broker就是一个kafka实例，还是说broker就是一台kafka服务？
3.文中提到的“重平衡”，是不是就是再分配，kakfa中应该有再分配的这个概念，这两个是不是同一个？
作者回复: 1. 类似于Hadoop中的rack。一旦配置了rack，Kafka会尽力保证把副本分配在多个rack上
2. 启动broker进程就是启动一个Kafka服务器
3. 个人觉得这是两个概念。我倾向于认为rebalance是重平衡，reassignment是再分配。这两个在Kafka中是不同的操作
2019-09-19



clz1341521
kfk领导者副本分布在多台机器上已实现负载均衡，另外leader ，follower之间数据需要同步可能会造成数据不一致问题。
2019-09-17



大牛凯
老师好，请问leader partition是随机分给不同broker的吗？
作者回复: 默认情况下，所有分区的所有副本排序之后按照round robin策略依次放入不同broker上
2019-09-13

1


云师兄
读取从库是希望可以平衡负载，kafka通过了分区和消费组已经实现了。而且副本涉及到分布式一致性问题，kafka的isr机制会存在部分临时不一致情况，不适合客户端在多个副本之间切换读取
2019-09-11



兔2🐰🍃
老师您好，结合结尾的图来理解副本，是不是针对集群而言的，比如10个Broker, 每个分区都有10个副本，包含1个Leader副本，9个Follower副本，Leader按照某策略分布在不同的broker上？ 是这样理解吗？
作者回复: 是这样的
2019-08-31



JasonZhi
老师，为什么P2P模型还会有topic，按道理只有发布订阅模式才会有topic 的概念吧？
作者回复: 设计一套概念能支持两种模型岂不是很好的做法?
2019-08-23



欧文
请问最后那个图用什么工具画的
作者回复: PPT
2019-08-20



飞翔的鼠标垫
老师，你好。
1.假如我向分区中发了2条消息，如果第一条消息确认被消费掉了，那么第二条消息的offset还是1吗，会变成0吗？
2.如果问题1里的offset不变，那么消费者位移直接用offset就可以了吧，反正该消息在分区内唯一又不会变，为什么要多整出个消费者位移的概念？
作者回复: 1. 消息一旦被写入到分区日志中位移就不会变化了
2. 消费者位移是表示消费者进度的。每个消费者都有自己的进度，因此引入了消费者位移
2019-08-18



秋天
有并发问题吧
2019-08-15



godtrue
课前思考
1：目前所知的消息引擎系统中的术语
1-1：生产者——生产消息的应用
1-2：消费者——消费消息的应用
1-3：主题——连接生产者和消费者，让消息可以流转的东西，对于主题这个东西理解的就不太好，他的本质是啥呢？只知道他是一个具有唯一性的字符串。另外，这里的生产者和消费者，可以没有任何关系，并且可以时是M：N的关系。
1-4：broker——消息引擎系统的服务端，是生产者和消费者的消息传输的链接器，这也理解的不太好，不知道他究竟是个什么东西，也是一个应用，只是功能的特点像一个连接器嘛？
1-5：消息——消息引擎系统处理的对象，消息引擎系统是咋处理的呢？就倒一道手，传输一下嘛？
为了高可用性会多弄一些副本？为了数据分析，持久化一下？为了传输编码解码？为了安全加密解密？为了性能压缩解压缩？
课后思考
1：看完这篇文章，又丰富了一些术语，比如：
1-1：分区——一个有序不变的消息序列，一个主题可以有多个分区。
1-2：消息位移——表示分区中每条消息的信息，是一个单调自增且不变的值。我的理解，就是消息在分区中的位置。
1-3：消费者位移——表示消费者消费的进度，每个消费者都有自己的消费者位移。我的理解是，消费者消费到那条消息了。
1-4：消费者组——多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞出量。我的理解，就是多个消费者实例在一块，一起消费一种消息。
1-5：副本——分区层级下的概念，指一条消息可以有多个完全一样的存在，存储在不同的地方以实现数据的高可用。
1-6：领导者副本——与客户端程序进行交互
1-7：追随者副本——与领导者副本保持同步
1-8：重平衡——消费者组内某个消费者实例宕机时，其他消费者实例自动重新分配此主题的分区消费的过程。
1-9：点对点模式——A应用的消息只能有B应用来消费
1-10：发布/订阅模式——消息的生产和消费者的关系是M：N
2：kafka特性的支撑因素
高可用——分布式，broker实例部署分布式、数据存储分布式
高吞出——消息日志采用顺序IO写、消费者组，多个消费者实例同时消费
一图胜千言，老师最后的图非常好，如果能将一个消息的生命周期也画出来就更好了，我觉得从简单到复杂的讲一下会非常有助于理解kafka，比如：只有一个生产者、一个消费者、一个主题、一个broker，一个分区的情况下，一条消息是怎么一步步传输的。然后再复杂一下，再讲解一下消息的流转过程。这样感觉对于kafka是怎么处理消息的会一下子清晰起来，拉一条主线，然后再不断的丰富它。
看完所有的评论对于以下概念又多了一些认知，但也有些疑问。
1：kafka是使用scala语言编写的，是否也像JAVA一样需要虚拟机的来提供运行环境的支持？
2：在一台服务器上运行一次kafka的程序就表示有一个broker的进程了是吗？并且在一台服务器上可以运行n次kafka的程序相当于有n个broker的进程了是吗？
3：“虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一。”这段描述，我没明白不同的broker是什么意思？是相对什么来讲的？还是说一个kafka程序跑起来之后，可以创建多个主题，每个主题可以有多个broker，每个broker可以有多个分区，每个分区可有多个副本，这些副本在多个机器上。不知这样理解是否正确？
2019-08-11



谢特
Kafka 的leader broker上的副本是领导者副本？
作者回复: 嗯嗯
2019-08-06



sun留白
有一个问题，如果一个broker主挂了，那么他的消费者位移，如何传递给从？胡大大
作者回复: 内部位移topic的写入都是acks=all的，所以follower副本与leader副本实时同步
2019-07-31

1


君莫笑
补充上一条留言。
官方：
第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。
第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。
第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。最后，客户端程序只能与分区的领导者副本进行交互
我瞎想的：
第一层是主题层，每个主题可以配置N个副本，N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。
第二层是消息层，副本中包含若干条消息，每条消息的位移从 0 开始，依次递增。最后，客户端程序只能与主题的领导者副本进行交互

我瞎想的这个，把主题层的粒度降低到官方的分区粒度一样，，这样应该可以吧，，
2019-07-26



君莫笑
老师，对于分区概念的来源，“倘若领导者副本积累了太多的数据以至于单台 Broker 机器都无法容纳了，此时应该怎么办呢？一个很自然的想法就是，能否把数据分割成多份保存在不同的 Broker 上”。这里有一个疑惑。
     这里的意思是，（先假设这里的broker只有一个opic）分区是为了解决单台broker中topic无法容纳太多数据而引入的，将其分割成多份也可以保存在不同机器上以提高吞吐量。那么如果单个分区积累了太多数据又该如何？单个分区积累数据太多又是如何解决得，如果有某种解决方式，为何当时不直接运用到topic上呢？可能描述的不太清楚，请老师指点。

2019-07-26



Wenthkim
请问老师，文章中的图是用什么工具画的
作者回复: powerpoint
2019-07-18



-W.LI-
我觉得在kafka中读数据=消费数据，如果flower可以读。就和MySQL的从库可以写一样了。。。所以MySQL从库不能写kafka的flower不能读很在理啊。MySQL的读是幂等操作kafka的读不是幂等操作。
2019-07-09



nickyi
你好，请教个问题，kafka在你实际工作中用在了什么业务场景，会涉及到钱吗，怎么保证算的正确。
2019-07-08



forever
谢谢老师讲解，有一个疑问就是，图上只有3个分区，画了4个消费者，是不是有一个会闲置，真实中我们是不是设置消费者数不超过partition数，这样不浪费资源
2019-07-05



beiliu
您好，老师，请问怎么使用kafka自带的shell脚本完成基于某个时间戳开始的10条消息的消费，打印出消息本身的time stamp,partition,offset和消息本身的内容
作者回复: Kafka自带脚本无法实现这个功能。。。。只能自己编写程序实现
2019-06-25



韩大
太棒了，我之前花了很长时间才理解的几个元素，让老师这么轻松的，非常完美的描述下来了，太👍！
2019-06-21



王大伟
Follower和leader是针对副本而言的吗？是否意味着，假设一个Topic有5个分区，每个分区有2个replica，那么系统中可能会有5个leader？
作者回复: 嗯嗯，正常情况下每个分区都应该有一个leader和若干个（也可能是0个）follower。
2019-06-18



每天晒白牙
我认为kafka不采用follower副本读数据功能，有两点原因
1.mysql的主写从读的目的是为了负载均衡，分担主节点的压力
而kafka通过分区解决了这个问题
2.如果kafka的follower副本提供读功能，会出现数据不一致的情况，毕竟kafka的副本同步采用的是poll，mysql的复制通过binlog会实现最终的一致性
还望老师指点
作者回复: 针对第二点，我倒觉得Kafka和MySQL都是采用基于日志（log-based）的结构来做的同步，本质上都属于CDC(capture data change)。MySQL也有主从不一致的问题。
2019-06-18



。
老师想问下 这个副本既然是做数据冗余之用，那是不是一个leader只需要有一个副本就好了？
作者回复: 嗯嗯，其实我也是觉得业界的Hadoop三副本是很保守的方案。我们一般公司里面的业务消息也没那么值钱，那必要存两份。通常情况下冗余一份足够了：）

如果你觉得你的业务消息很值钱的话，那么保存多份是有意义的
2019-06-17



亦然
课后思考题
看了大家的回答，我也从功能角度说说看吧。
Master-Slave 模式主要是为了减轻读的压力，而对于一致性的话，数据库这种只需要保证最终一致性即可。但是对于 Kafka 这种消息系统来说，从每个分区读也是实现了负载均衡，但是需要保证强一致性，避免不同节点读到数据滞后等情况。
作者回复: 同意：）
2019-06-16



哥本
老师讲解的很精彩！但是图太少，对于初学者不易理解，希望老师能多加些图 谢谢
作者回复: 好好，感谢您的建议。后面我会增加更多的图例：）
2019-06-15



rm -rf 😊ི
我的理解是，kafka如果提供副本的读，可能会导致消息被重复消费，不好保证消费者的幂等性。mysql不一样，读的内容是完全可以重复并且不需要幂等性保障
作者回复: 有一定道理：）
2019-06-15



青莲
1、同一消费者实例在正常运行时只能消费同一分区，如果追随者副本提供读服务，意味着每个消费者需同时维护多个副本之间offset
2、最最重要的是 同时读取副本会造成消息的重复消费，乱序问题，会引发一系统分布式问题
3、从效率上来讲副本提供读取服务带不了一丁点收益
2019-06-14



wrzgeek
小白提问:
1. leader 副本分布在哪个broker上随机的吗？还是有什么机制
2. 如文中最后一个图所示，假如broker1挂掉，broker2上的follower副本会变为leader副本吗？假如不止一个follower副本，是不是有某种选举方式来决定哪个follower副本会升级为leader副本？
作者回复: 1. 有算法，不是随机的。其实不只是leader，整个副本在broker上的分配策略大体上都遵循轮询的公平法则。
2. 从follower中选择leader的算法如下：
 2.1 从ISR中选择存活的第一个副本为新leader
 2.2 如果ISR为空，看是否开启了unclean leader选举，如果没有开启，那么Kafka干脆就不选leader了，直接将分区置于不可用状态；否则Kafka就从剩下的存活副本中选第一个副本作为leader（这里的顺序就是ZooKeeper中保存的副本集合顺序，即assigned_replicas项）
2019-06-14



runner
可以增加一些图，对初学者更容易理解。
2019-06-14



在路上
追随者副本拉取领导者副本不是实时的，允许读取追随者副本会导致读取数据不一致
2019-06-14



风起青萍
胡先生，讲的很棒。
2019-06-12



18210067841
如果消费者都读follower就没有办法保证有序了
2019-06-12



小飞
“使用ack=-1 , min-replica=1 （replica=2) 应该就可以。
对生产来说，可以兼顾生产不丢消息，又不需要所有的follower全部完成复制”

acks=-1了leader会等所有follower都同步了该消息后才会返回给client“

胡老师， 这回复可能不太准确。 
按照Kafka 官方文档的解释， 
“When a producer sets acks to "all" (or "-1"), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend).
When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of "all". This will ensure that the producer raises an exception if a majority of replicas do not receive a write."
min.insync.replicas =1 , replica =2 , ACK = -1 ， 只需要leader 和之外的一个replica 返回即可。 不需要所有的follower 返回。 
请胡老师再帮确认下。 哈哈
作者回复: 没有冒犯的意思，不过你的理解是错误的。minIsr是为了确保因ISR shrink而导致hw过早移动而带来的“假”同步。如果ISR没有发生意外shrink，acks=-1的含义就是只有当所有副本都同步了消息broker才返回response。

还是那句话，minIsr是为了确保ISR意外shrink而依然保持持久化的手段
2019-06-12



开水
一个partition的一个副本会全部存储在一台broker上么？
作者回复: 是的
2019-06-12



开水
Confluent里面的一个组件Avro schema registry server 就是用Kafka中的一个topic来当schema内容和版本存储用的。目前还没弄懂原理，但是已经单独把这个功能拆出来当系统内部消息统一化管理的组件来用了。求大神讲讲Kafka具体是怎么当分布式存储来使用的😁
作者回复: schema registry主要是用于管理topic消息格式的前后向兼容的。比如公司里面两个部门A和B，A向Kafka写消息，B从Kafka读消息。A和B要约定好消息格式。选择一个对兼容性支持比较好的schema自然是皆大欢喜。其实这也是PB、Thrift和Avro这类编码格式发展的初衷。

至于分布式存储，我专栏里面也写了Kafka第一作者Jay Kreps写过一篇文章讨论过Kafka当data store的可能性。我的观点是：姑且一听即可，实际使用过程中我没有见过把Kafka真当做持久化存储来使用的场景 。
2019-06-12



风中花
老师，我想问一个问题，我也是在画图过程发现 ，Follower副本 只能向别的broker leader 发送请求拉取信息吗，它不向自己所在得broker（leader) 发送请求吗，还是说他们是交互得，这个请求拉取得过程是怎么样得了？ 多谢指导！
作者回复: 同一个分区下的所有副本必然在不同的broker上，因此不会存在同一个分区下follower副本和leader副本在同一台broker上的情况
2019-06-11



霄嵩
老师写的很棒，最后一张图一目了然。
2019-06-11



风中花
胡老师，我也建议图文并茂，适当增加图图，我也学习过大数据课程，那个在线教育，他得图搭配非常到位，配合文字，描述特别清楚，影响也清楚。希望不要增加老师得负担！
2019-06-11



歪曲丶
kafka写副本很耗时 ack 如果为all 严重影响消费 mysql通过binlog 因为主已经落盘 从可以提供读 但也会存在一致性问题 但是不影响并发 不存在丢数据
2019-06-11



小智e
需要来几张图片，毕竟一图胜千言，一口气都下来，没看到一张图示
作者回复: 嗯嗯，感谢您的反馈。我新加了一张图，希望能够帮助您更好地理解这些概念。
2019-06-11



永光
谢谢老师之前的回答：
对于之前的回答还有点小疑惑：
1、客户端会首先请求topic分区的leader副本在哪个broker上，内部自动执行的，你无需操心； 
     哈哈，确实不用操心，只是特别好奇他是怎么选的？ 因为每个topic的每个分区leader还不一样。

2、重平衡时每个消费者都会尽力去做一次位移提交（如果它会提交位移的话），这样当rebalance完成后Kafka会告诉它们订阅分区当前消费到了那里。
我理解你说的应该是在检测到有节点挂了，kafka会进行重平衡，此时未挂的节点会尽力提交自己的位移，对吧？但是针对挂了的节点我理解是没法位移提交的，针对没有没有位移提交怎么处理呀？

真的感谢老师的回答。
作者回复: 1. 客户端发送Metadata请求获取每个topic分区的leader，之后再发送真实的数据请求（Produce请求或Fetch请求）
2. 如果消费者挂了自然是没法提交位移，所以有重复消费的问题。Kafka一直是承认这一点的啊，即消费者端存在消息被消费多次的情况
2019-06-10



雾里晨光
老师，您好。这些术语的关系不太容易理解，如果能有张逻辑关系图，可能更容易理解一点。
作者回复: 好的。图马上就补上:)
2019-06-10



demmm
这里面的点对点指的是同一条消息只能被下游的一个消费者消费，其他消费者则不能染指。在 Kafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。

所以说kafka是采用的p2p还是发布 / 订阅模型啊？



作者回复: 应该这么说：Kafka通过消费者组机制同时实现了对p2p和发布/订阅模型的支持。
2019-06-10



可以
打卡
2019-06-10



Garfield
老师，Consumer Group 是多个实例组成的一个组，同时消费多个分区，Brokers会将同一个消息往多个group推送吧，这样有重复消费问题，不太理解怎么做高吞吐。
作者回复: 所谓的重复消费一般只是同一条消息被一个消费者处理了多次。多个消费者消费同一条消息没问题的。
2019-06-10



小飞
老师评论中提到的生产“折中”方案，兼顾可靠性和效率的方法，其实是有的！
使用ack=-1 , min-replica=1 （replica=2) 应该就可以。
对生产来说，可以兼顾生产不丢消息，又不需要所有的follower全部完成复制。消息会被发送成功。
对消费来说，可能消息还是无法第一时间被消费到，需要所有isr 完成消息得同步，完成commit. 更新high water. 才能被消费。
老师说这样对吗？
作者回复: “使用ack=-1 , min-replica=1 （replica=2) 应该就可以。
对生产来说，可以兼顾生产不丢消息，又不需要所有的follower全部完成复制”

acks=-1了leader会等所有follower都同步了该消息后才会返回给client
2019-06-09



莫问流年
我觉得Kafka之所以不像Mysql那样对外提供服务：一方面因为Kafka的Topic分区已经提供了集群读写能力；另一方面kafka的读写都属于顺序I/O，相对于Mysql的随机I/O效率已经很高。
2019-06-09



南辕北辙
与rabbitmq的镜像队列一样，因为这里负载层面是在分区上，而不像mysql上负载在机器上了。不然反而容易造成单节点负载过高。
2019-06-09



Icedmaze
老师，之后的课程是否会讲到关于Kafka的Rebalance导致的一些业务上的问题（如数据重复消费问题，消费顺序问题）的解决方案和实例么，还是说往往该类问题都是通过业务的层面钱解决该问题。
作者回复: 后面会有Rebalance的详细介绍~~
2019-06-08



星辰
也就是说 从kafka的follower replica中读取数据 是没有必要的 而且维护起来很麻烦 是吗？😂😂😂

ps:我是kafka小白😂😂😂
作者回复: 从目前的设计来看，从follower读取数据的确是弊端大于收益。当然这不代表未来不会变更。
2019-06-08



giantbroom
请教一个问题，一个分区包含leader和follower副本，这些副本的持久化是否可以夸broker，就是说分散存储在不同的虚拟机上？如果不能的话，如果分区所在的机器挂了，所有数据岂不是都丢了？
作者回复: 嗯，Kafka对于不丢消息是有条件的，不可能保证任何条件下都不丢失消息。
2019-06-08

1


天下行走
我感觉应该是：如果可从追随者broker都，那么一致性要求就要很高，所有的消息必须全部同步完毕才能开放给消费者都；而目前这种模式追随者只需保证最终一致性立刻。后者对消息的可见延迟很低
2019-06-07



不了峰
请教一下，如果一个生产者，向一个主题一次写100万条消息，那他是会写到这个主题的一个分区还是写到多个分区里面？
谢谢。
作者回复: 取决于很多因素。首先你的主题有几个分区？另外你的生产者是否指定了消息要被发送的分区？正常情况下，如果你有多个分区且没有指定特定的目标分区，那么producer的确会把消息发送到多个分区。
2019-06-07

1


77
老师，p2p和topic的区别是不是就是同一个分区是否允许多个消费者消费的区别
作者回复: 在我看来，这两者的区别主要是通过消费者组体现的。同一组内，每个分区只能被一个消费者消费；但还是可以被组外的其他消费者消费。
2019-06-07



xyf
老师您好，我在用kafka的时候发现zk如果异常后会偶现kafka连接数暴增的情况，最终超过操作系统的最大连接数后服务就挂掉了，并且重启服务后连接数还会立马涨上来，请问下这个问题有什么好的处理方式，感谢。
作者回复: 感觉还是有很多“僵尸”连接导致的，建议复现后能提供更为详细的数据或是直接到社区提交一个jira看一下。
2019-06-07



蒙开强
老师，你好，我读了这篇专栏后有个问题咨询一下你，消费客户端消费topic的时候只指定了一个消费组，没有指定消费组里具体多少实例，是内部有什么策略或者机制进行分配么，怎么体现出这个消费组里有多少消费实例呢，理想情况消费实例与topic分区数相等是最好的，但消费端程序里API没有这设置项。
作者回复: 配置了相同group. id的消费者自动成为一个组。分区分配有消费者指定的分配策略来决定，有个专门的参数来控制此事，而不是在api中体现的。
2019-06-06



川杰
感谢回答。其实我们公司是.net，我们的消息队列是自研的，我自己的思路是，利用socket，当有消息过来时，封装路由信息，利用socket去转发消息，当然里面还涉及一个单位时间上游过来大量消息的情况的处理，比如利用线程池去做消息的路由等。不知道这种思路可行吗？
作者回复: 我觉的可行
2019-06-06



liurh
没有提到broker，分区是怎么分布在broker上的
作者回复: 嗯嗯，严格说这属于创建topic时的分区分配策略。实话说是有点复杂的。。。。
2019-06-06



吃饭饭
我记得在配置时 Replication 的个数小于等于 Broker 个数^_^
2019-06-06



且听风吟
是否可以在消费端内部暴露一个rpc接口，这样实现消息的push操作时，实际上是通过服务端调用rpc接口实现的，而不是通过消费端的轮询。(不知道kafka怎么做的push方式，qmq好像是消费端有个dubbo接口接收消息)
作者回复: Kafka毕竟是起家于大数据领域，如果碰到producer TPS超低以至于我们都要思考consumer PULL模型是否合理的场景，那么也可以思考一下是否真需要使用Kafka：）
2019-06-06



川杰
老师请教一个问题，对于发布/订阅者模式来说，消息往往是存储在某种形式的队列中的，那如何把这个队列中的消息推送给消费者呢？我们公司的做法就是利用一个线程去轮询将消息分发到各自的消费者中；可是，从实际业务场景来看，往往消息生产者只在某个特定的时间段去生产消息，而且消息是少量的，几十到几百个；服务器一直开一个线程去轮询我总觉得有些浪费资源；请问除了轮询以外有没有其他办法？
作者回复: 目前看很难。Kafka不能推送消息给consumer。Consumer只能不断地轮训去获取消息。从Kafka流向consumer的唯一方式就是通过poll。另外维持一个长连接去轮训的开销通常也没有你想的那么大，特别是Kafka用的是Linux上的epoll，性能还不错，至少比select好。
2019-06-06



Mr.Panda
问题：为什么 Kafka 不像 MySQL 那样允许追随者副本对外提供读服务？
答：
1.保证消息的新鲜。只读leader副本，保证数据的最新。追随副本同步最新数据存在延迟。
2.已设计了分区机制和消费者组机制，解决了吞吐量问题，无需追随副本再去分担。
老师请解惑： 每个分区下的多个副本，是和对应分区在同个服务器下的吗？还是说可以分散在多个服务器中，可以避免一个服务器硬盘损坏了，也能发挥副本的作用，即高可用。
作者回复: 同一分区下的所有副本一定分散在不同的broker上（是broker，不是机器，因为可能一个机器上有多个broker）。

其实，每个broker也可以配置多块物理磁盘，而且自Kafka 1.0开始支持JBOD（Just a Bunch Of Disks）了，单块磁盘的损坏不会令broker宕机了。总之这一切都是为了提升高可用。
2019-06-06



柠檬C
不提供主写从读，第一是要保证一致性，逻辑就更复杂；第二是kafka相比redis还需要刷盘，流程更长；第三本身kafka通过partition已经实现了良好的负载均衡了
2019-06-06



皮皮
前面有同学在问replica的leader和follower之间如何复制数据保证消息的持久化的问题，我了解的是有3种模式：1.生产者消息发过来以后，写leader成功后即告知生产者成功，然后异步的将消息同步给其他follower，这种方式效率最高，但可能丢数据；2.同步等待所有follower都复制成功后通知生产者消息发送成功，这样不会丢数据，但效率不高；3.折中的办法，同步等待部分follower复制成功，如1个follower复制成功再返回，这样兼顾效率和消息的持久化。具体选择哪种要根据业务情况进行选择。说的不对的地方请老师斧正。
作者回复: 目前Kafka不支持第三种“折中”办法。。。要么只写leader，要么所有follower全部同步。但是，我同意很多分布式系统是可以配置同步follower和异步follower共存的，比如一个同步follower+N-1个异步follower的伪同步。Facebook的MySQL就是这个原理，参见http://yoshinorimatsunobu.blogspot.com/2014/04/semi-synchronous-replication-at-facebook.html
2019-06-06



你看起来很好吃
胡老师您好，讲得真好，通俗易懂，感觉很值。
不过我有一点困惑，想咨询一下您，我是一名刚从android转到后端的开发，现在工作里大部分工作都是做一些业务逻辑和使用一些常用的中间件，公司的业务也很难遇到真正的解决高并发，也很难遇到那种需要设计很好的分布式，高可用的系统。但是我想了解这些，想知道如果要做，要怎么来实现。
然后我看这讲中有讲kafka有这种高可用，分布式的设计，所以我想我是否可以通过阅读kafka这相关的源码和设计，学习这样的系统如何设计。那如果可以的话，有没有好的相关的书可以推荐一下呢？感觉胡老师
作者回复: 阅读Kafka源码是一件需要长期坚持的事情，如果你真的决定了就去直接看源码，不需要什么书籍。只要坚持下来一定会有收获！如果你想学分布式系统，我推荐《Designing Data-Intensive Applications》，多看几遍~~
2019-06-06



口天小山己
follower副本向leader副本pull数据，是要等pull成功了才返回给生产者这条信息发送成功了吗，还是生产者数据发送到leader副本就算这条数据发送成功了，后面follower副本自己向生产者pull数据，保证最终一致性？如果是要等follower副本pull成功了才返回给生产者这条数据发送成功的话，这个pull不是异步的吗，是怎么通知生产者这次follower副本pull成功呢？
作者回复: producer是否等待follower拉取成功取决于producer端参数acks的设置。至于follower异步同步的完整机制在专栏的后面有详细的介绍~~
2019-06-06



美美
副本提供对外读要解决的问题：
1 可读的消息通过高水位隔离，HWM meta data需要保证一致性
2 rebalance 和 lead replica failover需要保consumer offset一致性
2019-06-06



pain
老师，如果消费者组里面的消费者数量比分区数多，会有部分消费者闲置吗，还是多个消费者一直竞争。应该怎么选择分区与消费者的数量呢
作者回复: 理想情况下消费者数量=消费者组订阅主题的总分区数，当然也不是绝对的。不过能肯定的是，如果消费者数>总分区数，那么就会有消费者闲置
2019-06-06



Summer
mysql读写分离是为了把大的“读”流量落到读库上，避免高并发下去锁表。

而kafka是以 “追加”形式写，所以不存在随机io问题
2019-06-06



cricket1981
因为ISR机制，follower不一定具备leader一样全量最新消息集，为防止读不一致，所以不支持。
2019-06-06



alwyn
那就是消费者数一般小于分区数，不然会有消费者处于空闲状态
作者回复: 消费者数<=分区数
2019-06-06



Johnson
个人觉得主要是实现读写分离的性价比不高，技术难度太大
作者回复: 社区最近正在讨论是否开放某些follower，允许其提供读服务。如果你有兴趣的话可以参与讨论：https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A+Allow+consumers+to+fetch+from+closest+replica
就我个人而言，感觉难度也没有想象的那么大：）
2019-06-06



伟子
我记得kafka中是有保证领导者和追随者的数据一致性的机制的，即生产者要收到领导者反馈的和追随者同步消息成功的消息后才发送下一条消息。我想，这样理论上追随者是可以提供对外服务的。但是这样会导致消息发布的速度变慢，相当于是用牺牲吞吐量来换取的。而kafka是有分区机制和消费者组的机制来确保吞吐量的。所以，追随者不提供对外服务是不是为了不影响吞吐量？
作者回复: 实话实说我们毕竟不是Kafka的作者，也许只能根据我们自己的理解来揣测Kafka的设计。我不能说你的这个观点是错误的，只是就我个人而言，为了避免处理一致性问题是这么设计的主要原因：）
2019-06-06



杨俊
领导者将数据同步到追随者副本既不是同步复制又不是异步复制，有一个isr列表维护，追随者副本自己去拉数据，有时候可能网络问题导致追随者副本之间存在数据不一致问题，高低水位不一样，isr列表的副本数也会不一样
作者回复: Kafka的副本拉取是完全异步的。另外实际上最新版本已经不单纯依赖高水位来判断了，而是依靠leader epoch
2019-06-06



mini希
追随者副本同步数据有一定延迟吧，可能造成多个客户端读取到的数据不一致或者同一个客户端访问不同追随者副本不一致吧，
作者回复: follower不对外提供服务，所以不会出现这种情况。但可能的情形是因为客户端要等follower副本同步而出现的延时
2019-06-06



kxct
副本不对外提供服务是为了强一致性吧
作者回复: 不对外提供服务的确可以避免很多因异步副本拉取出现lag导致的一致性问题。
2019-06-06



一步
在 P2P 模型中，当某个消费者消费一条数据成功ack后，数据不会在对应的Partiton删除吗？ 还是等待定时任务检查是否删除呢？
作者回复: 如果是在Kafka中，消息删除与否与消费者没有关系，受Kafka自己的留存策略控制，也就是你说的定时任务检查
2019-06-06



一步
至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步...
kafka 不是领导者副本向追随者副本 推送消息吗？ 这里说的是追随者副本向领导者副本拉取消息？


极客时间版权所有: https://time.geekbang.org/column/article/99318
作者回复: Kafka不是PUSH模型，而是PULL模型，即follower副本不断地从leader处拉取消息。
2019-06-06



周小桥
这里的术语介绍，在阿里一面的时候有被问到。

为什么副本不提供对外读？

我认为这个副本只是提供一个数据跟leader的同步，和当leader故障后能进行切换。还有消费者读取数据是根据offset去读取的，一份文件够了。
作者回复: Kafka不采用主从分离的讨论最近火起来了。如果要让follower抗读，需要解决很多一致性的问题，另外Kafka也不属于典型的读多写少场景，主从分离的优势不明显。
2019-06-06



innocent
是否是为了保证消息的一致性
作者回复: 能否具体说说消息一致性的含义？在分布式系统中一致性这个概念太大了，可能有很多意思。在Kafka中多指的是leader和follower之间的一致性。不知道你是否指这个？如果是，那么Kafka通过很多机制来确保两者的最终一致性。
2019-06-06


