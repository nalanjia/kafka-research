-------------------------------------------------------------
kafka_2.12-2.3.1.tgz
http://kafka.apache.org/23/documentation.html
Kafka 2.3 Documentation

3. CONFIGURATION
	3.1 Broker Configs
-------------------------------------------------------------
数一数下边的参数，一共是183个
右边有★，表示接触过，下方会有详细介绍

zookeeper.connect
advertised.host.name
advertised.listeners
advertised.port
auto.create.topics.enable
auto.leader.rebalance.enable
background.threads
broker.id
compression.type
control.plane.listener.name
delete.topic.enable
host.name
leader.imbalance.check.interval.seconds
leader.imbalance.per.broker.percentage
listeners
log.dir
log.dirs
log.flush.interval.messages
log.flush.interval.ms
log.flush.offset.checkpoint.interval.ms
log.flush.scheduler.interval.ms
log.flush.start.offset.checkpoint.interval.ms
log.retention.bytes
log.retention.hours
log.retention.minutes
log.retention.ms
log.roll.hours
log.roll.jitter.hours
log.roll.jitter.ms
log.roll.ms
log.segment.bytes
log.segment.delete.delay.ms
message.max.bytes
min.insync.replicas
num.io.threads
num.network.threads
num.recovery.threads.per.data.dir
num.replica.alter.log.dirs.threads
num.replica.fetchers
offset.metadata.max.bytes
offsets.commit.required.acks
offsets.commit.timeout.ms
offsets.load.buffer.size
offsets.retention.check.interval.ms
offsets.retention.minutes
offsets.topic.compression.codec
offsets.topic.num.partitions
offsets.topic.replication.factor
offsets.topic.segment.bytes
port
queued.max.requests
quota.consumer.default
quota.producer.default
replica.fetch.min.bytes
replica.fetch.wait.max.ms
replica.high.watermark.checkpoint.interval.ms
replica.lag.time.max.ms
replica.socket.receive.buffer.bytes
replica.socket.timeout.ms
request.timeout.ms
socket.receive.buffer.bytes
socket.request.max.bytes
socket.send.buffer.bytes
transaction.max.timeout.ms
transaction.state.log.load.buffer.size
transaction.state.log.min.isr
transaction.state.log.num.partitions
transaction.state.log.replication.factor
transaction.state.log.segment.bytes
transactional.id.expiration.ms
unclean.leader.election.enable
zookeeper.connection.timeout.ms
zookeeper.max.in.flight.requests
zookeeper.session.timeout.ms
zookeeper.set.acl
broker.id.generation.enable
broker.rack
connections.max.idle.ms
connections.max.reauth.ms
controlled.shutdown.enable
controlled.shutdown.max.retries
controlled.shutdown.retry.backoff.ms
controller.socket.timeout.ms
default.replication.factor
delegation.token.expiry.time.ms
delegation.token.master.key
delegation.token.max.lifetime.ms
delete.records.purgatory.purge.interval.requests
fetch.purgatory.purge.interval.requests
group.initial.rebalance.delay.ms
group.max.session.timeout.ms
group.max.size
group.min.session.timeout.ms
inter.broker.listener.name
inter.broker.protocol.version
log.cleaner.backoff.ms
log.cleaner.dedupe.buffer.size
log.cleaner.delete.retention.ms
log.cleaner.enable
log.cleaner.io.buffer.load.factor
log.cleaner.io.buffer.size
log.cleaner.io.max.bytes.per.second
log.cleaner.max.compaction.lag.ms
log.cleaner.min.cleanable.ratio
log.cleaner.min.compaction.lag.ms
log.cleaner.threads
log.cleanup.policy
log.index.interval.bytes
log.index.size.max.bytes
log.message.format.version
log.message.timestamp.difference.max.ms
log.message.timestamp.type
log.preallocate
log.retention.check.interval.ms
max.connections
max.connections.per.ip
max.connections.per.ip.overrides
max.incremental.fetch.session.cache.slots
num.partitions
password.encoder.old.secret
password.encoder.secret
principal.builder.class
producer.purgatory.purge.interval.requests
queued.max.request.bytes
replica.fetch.backoff.ms
replica.fetch.max.bytes
replica.fetch.response.max.bytes
reserved.broker.max.id
sasl.client.callback.handler.class
sasl.enabled.mechanisms
sasl.jaas.config
sasl.kerberos.kinit.cmd
sasl.kerberos.min.time.before.relogin
sasl.kerberos.principal.to.local.rules
sasl.kerberos.service.name
sasl.kerberos.ticket.renew.jitter
sasl.kerberos.ticket.renew.window.factor
sasl.login.callback.handler.class
sasl.login.class
sasl.login.refresh.buffer.seconds
sasl.login.refresh.min.period.seconds
sasl.login.refresh.window.factor
sasl.login.refresh.window.jitter
sasl.mechanism.inter.broker.protocol
sasl.server.callback.handler.class
security.inter.broker.protocol
ssl.cipher.suites
ssl.client.auth
ssl.enabled.protocols
ssl.key.password
ssl.keymanager.algorithm
ssl.keystore.location
ssl.keystore.password
ssl.keystore.type
ssl.protocol
ssl.provider
ssl.truststore.type
enable.idempotence
interceptor.classes
max.in.flight.requests.per.connection
metadata.max.age.ms
metric.reporters
metrics.num.samples
metrics.recording.level
metrics.sample.window.ms
reconnect.backoff.max.ms
reconnect.backoff.ms
retry.backoff.ms
sasl.kerberos.kinit.cmd
sasl.kerberos.min.time.before.relogin
sasl.kerberos.ticket.renew.jitter
sasl.kerberos.ticket.renew.window.factor
sasl.login.refresh.buffer.seconds
sasl.login.refresh.min.period.seconds
sasl.login.refresh.window.factor
sasl.login.refresh.window.jitter
ssl.cipher.suites
ssl.endpoint.identification.algorithm
ssl.keymanager.algorithm
ssl.secure.random.implementation
ssl.trustmanager.algorithm
transaction.timeout.ms
transactional.id


-------------------------------------------------------------
【接触过的参数】
auto.create.topics.enable=false









-------------------------------------------------------------
【案例】动态修改broker级别的参数log.message.timestamp.type
先介绍一下log.message.timestamp.type是什么，它是broker级别的参数，它的值有2个
CreateTime, LogAppendTime

设置
./kafka_2.12-2.3.1/bin/kafka-configs.sh \
--bootstrap-server **.**.**.**:9092 \
--entity-type brokers --entity-default --alter \
--add-config log.message.timestamp.type=LogAppendTime

查看
./kafka_2.12-2.3.1/bin/kafka-configs.sh \
--bootstrap-server **.**.**.**:9092 \
--entity-type brokers --entity-default --describe

命令帮助
./kafka_2.12-2.3.1/bin/kafka-configs.sh

验证，去运行DumpLogSegments，打印出消息的内部时间戳，可以看到LogAppendTime或CreateTime的字样
./kafka_2.12-2.3.1/bin/kafka-run-class.sh \
kafka.tools.DumpLogSegments --print-data-log \
--files /aebiz/2_softnor/15_kafka_binary/data_kafka/topic_1p_1r-0/00000000000000000000.log

